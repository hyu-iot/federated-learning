{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on cuda using PyTorch 2.0.0 and Flower 1.4.0\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "from typing import List, Tuple, Dict, Optional\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision.datasets import CIFAR10\n",
    "\n",
    "import flwr as fl\n",
    "from flwr.common import Metrics\n",
    "import flwr.common\n",
    "\n",
    "\n",
    "DEVICE = torch.device(\"cuda\")  # Try \"cuda\" to train on GPU\n",
    "print(\n",
    "    f\"Training on {DEVICE} using PyTorch {torch.__version__} and Flower {fl.__version__}\"\n",
    ")\n",
    "\n",
    "NUM_CLIENTS = 10\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
    ")\n",
    "trainset = CIFAR10(\"./dataset\", train=True, download=True, transform=transform)\n",
    "testset = CIFAR10(\"./dataset\", train=False, download=True, transform=transform)\n",
    "\n",
    "\n",
    "\n",
    "lengths = [45000, 5000]\n",
    "split_trainset, valset = random_split(trainset, lengths, torch.Generator().manual_seed(42)) \n",
    "    \n",
    "# 5000\n",
    "full_valloader = DataLoader(valset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "# 45000\n",
    "full_split_trainloader = DataLoader(split_trainset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "# 10000\n",
    "full_testloader = DataLoader(testset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "\n",
    "def load_datasets():\n",
    "    # Download and transform CIFAR-10 (train and test)\n",
    "    transform = transforms.Compose(\n",
    "        [transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
    "    )\n",
    "    trainset = CIFAR10(\"./dataset\", train=True, download=True, transform=transform)\n",
    "    testset = CIFAR10(\"./dataset\", train=False, download=True, transform=transform)\n",
    "\n",
    "\n",
    "\n",
    "    lengths = [45000, 5000]\n",
    "    split_trainset, valset = random_split(trainset, lengths, torch.Generator().manual_seed(42)) \n",
    "    \n",
    "    # 5000\n",
    "    full_valset = DataLoader(valset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "    # 45000\n",
    "    full_split_trainloader = DataLoader(split_trainset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    # 10000\n",
    "    full_testloader = DataLoader(testset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "    # Split training set into 10 partitions to simulate the individual dataset\n",
    "    partition_size = len(trainset) // NUM_CLIENTS\n",
    "    lengths = [partition_size] * NUM_CLIENTS\n",
    "    datasets= random_split(trainset, lengths, torch.Generator().manual_seed(42))\n",
    "\n",
    "    \n",
    "\n",
    "    # Split each partition into train/val and create DataLoader\n",
    "    trainloaders = []\n",
    "    valloaders = []\n",
    "    for idx, ds in enumerate(datasets):\n",
    "        len_val = len(ds) // 10  # 10 % validation set\n",
    "        len_train = len(ds) - len_val\n",
    "        lengths = [len_train, len_val]\n",
    "        ds_train, ds_val = random_split(ds, lengths, torch.Generator().manual_seed(42))\n",
    "        # Always splits in the same way.\n",
    "\n",
    "        # print(dict(Counter(ds_train.targets)))\n",
    "        # custom_subset(ds_train)\n",
    "        # arr = []\n",
    "        # print(\"ds_train\", idx)\n",
    "        # for a in ds_train:\n",
    "        #     arr.append(a[1])\n",
    "        # for i in range(10):\n",
    "        #     print(i, \":\", arr.count(i))\n",
    "        # Data is not perfectly distributed\n",
    "\n",
    "\n",
    "        trainloaders.append(DataLoader(ds_train, batch_size=BATCH_SIZE, shuffle=True))\n",
    "        valloaders.append(DataLoader(ds_val, batch_size=BATCH_SIZE))\n",
    "    testloader = DataLoader(testset, batch_size=BATCH_SIZE)\n",
    "    return trainloaders, valloaders, testloader\n",
    "\n",
    "\n",
    "trainloaders, valloaders, testloader = load_datasets()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "def train(net, trainloader, epochs: int, verbose=False):\n",
    "    \"\"\"Train the network on the training set.\"\"\"\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(net.parameters())\n",
    "    net.train()\n",
    "    for epoch in range(epochs):\n",
    "        correct, total, epoch_loss = 0, 0, 0.0\n",
    "        for images, labels in trainloader:\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # Metrics\n",
    "            epoch_loss += loss\n",
    "            total += labels.size(0)\n",
    "            correct += (torch.max(outputs.data, 1)[1] == labels).sum().item()\n",
    "        epoch_loss /= len(trainloader.dataset)\n",
    "        epoch_acc = correct / total\n",
    "        if verbose:\n",
    "            print(f\"Epoch {epoch+1}: train loss {epoch_loss}, accuracy {epoch_acc}\")\n",
    "\n",
    "\n",
    "def test(net, testloader):\n",
    "    \"\"\"Evaluate the network on the entire test set.\"\"\"\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    correct, total, loss = 0, 0, 0.0\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        for images, labels in testloader:\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "            outputs = net(images)\n",
    "            loss += criterion(outputs, labels).item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    loss /= len(testloader.dataset)\n",
    "    accuracy = correct / total\n",
    "    return loss, accuracy\n",
    "\n",
    "\n",
    "\n",
    "client_resources = None\n",
    "if DEVICE.type == \"cuda\":\n",
    "    client_resources = {\"num_gpus\": 1}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCH = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment on centralized manner.\n",
      "Epoch 1: validation loss 0.04441600443124771, accuracy 0.4778\n",
      "Epoch 2: validation loss 0.03931218582391739, accuracy 0.5474\n",
      "Epoch 3: validation loss 0.037541953146457675, accuracy 0.5656\n",
      "Final test set performance:\n",
      "\tloss 0.037185421848297116\n",
      "\taccuracy 0.5761\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>round</th>\n",
       "      <th>strategy</th>\n",
       "      <th>c_loss</th>\n",
       "      <th>c_accuracy</th>\n",
       "      <th>d_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Central</td>\n",
       "      <td>0.044416</td>\n",
       "      <td>0.4778</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Central</td>\n",
       "      <td>0.039312</td>\n",
       "      <td>0.5474</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Central</td>\n",
       "      <td>0.037542</td>\n",
       "      <td>0.5656</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   round strategy    c_loss  c_accuracy  d_accuracy\n",
       "0      0  Central  0.044416      0.4778         0.0\n",
       "0      1  Central  0.039312      0.5474         0.0\n",
       "0      2  Central  0.037542      0.5656         0.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "# 여기서는 10개로 나눈 것 중, 하나만 train 함.\n",
    "import pandas as pd\n",
    "df_final = pd.DataFrame()\n",
    "print(\"Experiment on centralized manner.\")\n",
    "\n",
    "net = Net().to(DEVICE)\n",
    "trained_path = \"./dataset/trained_centralized.pkl\"\n",
    "\n",
    "\n",
    "if not (os.path.isfile(trained_path)):\n",
    "    for epoch in range(EPOCH+1):\n",
    "        train(net, full_split_trainloader, 1)\n",
    "        loss, accuracy = test(net, full_valloader)\n",
    "        print(f\"Epoch {epoch+1}: validation loss {loss}, accuracy {accuracy}\")\n",
    "        df_result = pd.DataFrame()\n",
    "        df_result['round'] = epoch+1,\n",
    "        df_result['strategy'] = 'Central',\n",
    "        df_result['c_loss'] = loss,\n",
    "        df_result['c_accuracy'] = accuracy,\n",
    "        df_result['d_accuracy'] = 0.0\n",
    "\n",
    "        df_final = pd.concat([df_final, df_result], axis=0)\n",
    "\n",
    "    torch.save(net.state_dict(), trained_path)\n",
    "else :\n",
    "    net.load_state_dict(torch.load(trained_path))\n",
    "loss, accuracy = test(net, full_testloader)\n",
    "print(f\"Final test set performance:\\n\\tloss {loss}\\n\\taccuracy {accuracy}\")\n",
    "\n",
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_parameters(net) -> List[np.ndarray]:\n",
    "    return [val.cpu().numpy() for _, val in net.state_dict().items()]\n",
    "\n",
    "\n",
    "def set_parameters(net, parameters: List[np.ndarray]):\n",
    "    params_dict = zip(net.state_dict().keys(), parameters)\n",
    "    state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n",
    "    net.load_state_dict(state_dict, strict=True)\n",
    "\n",
    "class FlowerClient(fl.client.NumPyClient):\n",
    "    def __init__(self, net, trainloader, valloader):\n",
    "        self.net = net\n",
    "        self.trainloader = trainloader\n",
    "        self.valloader = valloader\n",
    "\n",
    "    def get_parameters(self, config):\n",
    "        return get_parameters(self.net)\n",
    "\n",
    "    def fit(self, parameters, config):\n",
    "        set_parameters(self.net, parameters)\n",
    "        train(self.net, self.trainloader, epochs=1)\n",
    "        return get_parameters(self.net), len(self.trainloader), {}\n",
    "\n",
    "    def evaluate(self, parameters, config):\n",
    "        set_parameters(self.net, parameters)\n",
    "        loss, accuracy = test(self.net, self.valloader)\n",
    "        print(f\"Accuracy {accuracy}\")\n",
    "        return float(loss), len(self.valloader), {\"accuracy\": float(accuracy)}\n",
    "    \n",
    "def client_fn(cid: str) -> FlowerClient:\n",
    "    \"\"\"Create a Flower client representing a single organization.\"\"\"\n",
    "\n",
    "    # Load model\n",
    "    net = Net().to(DEVICE)\n",
    "\n",
    "    # Load data (CIFAR-10)\n",
    "    # Note: each client gets a different trainloader/valloader, so each client\n",
    "    # will train and evaluate on their own unique data\n",
    "    trainloader = trainloaders[int(cid)]\n",
    "    valloader = valloaders[int(cid)]\n",
    "\n",
    "    # Create a  single Flower client representing a single organization\n",
    "    return FlowerClient(net, trainloader, valloader)\n",
    "    \n",
    "def weighted_average(metrics: List[Tuple[int, Metrics]]) -> Metrics:\n",
    "    # Multiply accuracy of each client by number of examples used\n",
    "    accuracies = [num_examples * m[\"accuracy\"] for num_examples, m in metrics]\n",
    "    examples = [num_examples for num_examples, _ in metrics]\n",
    "\n",
    "    # Aggregate and return custom metric (weighted average)\n",
    "    return {\"accuracy\": sum(accuracies) / sum(examples)}\n",
    "\n",
    "# The `evaluate` function will be by Flower called after every round\n",
    "def evaluate(\n",
    "    server_round: int,\n",
    "    parameters: fl.common.NDArrays,\n",
    "    config: Dict[str, fl.common.Scalar],\n",
    ") -> Optional[Tuple[float, Dict[str, fl.common.Scalar]]]:\n",
    "    net = Net().to(DEVICE)\n",
    "    valloader = valloaders[0]\n",
    "    set_parameters(net, parameters)  # Update model with the latest parameters\n",
    "    loss, accuracy = test(net, valloader)\n",
    "    print(f\"Server-side evaluation loss {loss} / accuracy {accuracy}\")\n",
    "    return loss, {\"accuracy\": accuracy}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fedavg = fl.server.strategy.FedAvg(\n",
    "    fraction_fit=1.0,\n",
    "    fraction_evaluate=0.5,\n",
    "    min_fit_clients=10,\n",
    "    min_evaluate_clients=5,\n",
    "    min_available_clients=10,\n",
    "    evaluate_metrics_aggregation_fn=weighted_average,   # aggregate evaluation of local model\n",
    "    evaluate_fn=evaluate,   # evaluate global model\n",
    "    initial_parameters=fl.common.ndarrays_to_parameters(get_parameters(Net())),\n",
    ")\n",
    "\n",
    "fedavgM = fl.server.strategy.FedAvgM(\n",
    "    fraction_fit=1.0,\n",
    "    fraction_evaluate=0.5,\n",
    "    min_fit_clients=10,\n",
    "    min_evaluate_clients=5,\n",
    "    min_available_clients=10,\n",
    "    evaluate_metrics_aggregation_fn=weighted_average,   # aggregate evaluation of local model\n",
    "    evaluate_fn=evaluate,   # evaluate global model\n",
    "    initial_parameters=fl.common.ndarrays_to_parameters(get_parameters(Net())),\n",
    ")\n",
    "\n",
    "# qfedavg = fl.server.strategy.QFedAvg(\n",
    "#     fraction_fit=1.0,\n",
    "#     fraction_evaluate=0.5,\n",
    "#     min_fit_clients=10,\n",
    "#     min_evaluate_clients=5,\n",
    "#     min_available_clients=10,\n",
    "#     evaluate_metrics_aggregation_fn=weighted_average,   # aggregate evaluation of local model\n",
    "#     evaluate_fn=evaluate,   # evaluate global model\n",
    "#     initial_parameters=fl.common.ndarrays_to_parameters(get_parameters(Net())),\n",
    "# )\n",
    "\n",
    "# ftfedavg = fl.server.strategy.FaultTolerantFedAvg(\n",
    "#     fraction_fit=1.0,\n",
    "#     fraction_evaluate=0.5,\n",
    "#     min_fit_clients=10,\n",
    "#     min_evaluate_clients=5,\n",
    "#     min_available_clients=10,\n",
    "#     evaluate_metrics_aggregation_fn=weighted_average,   # aggregate evaluation of local model\n",
    "#     evaluate_fn=evaluate,   # evaluate global model\n",
    "#     initial_parameters=fl.common.ndarrays_to_parameters(get_parameters(Net())),\n",
    "# )\n",
    "\n",
    "# fedopt = fl.server.strategy.FedOpt(\n",
    "#     fraction_fit=1.0,\n",
    "#     fraction_evaluate=0.5,\n",
    "#     min_fit_clients=10,\n",
    "#     min_evaluate_clients=5,\n",
    "#     min_available_clients=10,\n",
    "#     evaluate_metrics_aggregation_fn=weighted_average,   # aggregate evaluation of local model\n",
    "#     evaluate_fn=evaluate,   # evaluate global model\n",
    "#     initial_parameters=fl.common.ndarrays_to_parameters(get_parameters(Net())),\n",
    "# )\n",
    "\n",
    "# fedprox = fl.server.strategy.FedProx(\n",
    "#     fraction_fit=1.0,\n",
    "#     fraction_evaluate=0.5,\n",
    "#     min_fit_clients=10,\n",
    "#     min_evaluate_clients=5,\n",
    "#     min_available_clients=10,\n",
    "#     evaluate_metrics_aggregation_fn=weighted_average,   # aggregate evaluation of local model\n",
    "#     evaluate_fn=evaluate,   # evaluate global model\n",
    "#     initial_parameters=fl.common.ndarrays_to_parameters(get_parameters(Net())),\n",
    "#     proximal_mu=0.1,\n",
    "# )\n",
    "\n",
    "# fedadagrad = fl.server.strategy.FedAdagrad(\n",
    "#     fraction_fit=1.0,\n",
    "#     fraction_evaluate=0.5,\n",
    "#     min_fit_clients=10,\n",
    "#     min_evaluate_clients=5,\n",
    "#     min_available_clients=10,\n",
    "#     evaluate_metrics_aggregation_fn=weighted_average,   # aggregate evaluation of local model\n",
    "#     evaluate_fn=evaluate,   # evaluate global model\n",
    "#     initial_parameters=fl.common.ndarrays_to_parameters(get_parameters(Net())),\n",
    "# )\n",
    "\n",
    "# fedadam = fl.server.strategy.FedAdam(\n",
    "#     fraction_fit=1.0,\n",
    "#     fraction_evaluate=0.5,\n",
    "#     min_fit_clients=10,\n",
    "#     min_evaluate_clients=5,\n",
    "#     min_available_clients=10,\n",
    "#     evaluate_metrics_aggregation_fn=weighted_average,   # aggregate evaluation of local model\n",
    "#     evaluate_fn=evaluate,   # evaluate global model\n",
    "#     initial_parameters=fl.common.ndarrays_to_parameters(get_parameters(Net())),\n",
    "# )\n",
    "\n",
    "# fedyogi = fl.server.strategy.FedYogi(\n",
    "#     fraction_fit=1.0,\n",
    "#     fraction_evaluate=0.5,\n",
    "#     min_fit_clients=10,\n",
    "#     min_evaluate_clients=5,\n",
    "#     min_available_clients=10,\n",
    "#     evaluate_metrics_aggregation_fn=weighted_average,   # aggregate evaluation of local model\n",
    "#     evaluate_fn=evaluate,   # evaluate global model\n",
    "#     initial_parameters=fl.common.ndarrays_to_parameters(get_parameters(Net())),\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flwr 2023-05-02 10:28:45,703 | app.py:146 | Starting Flower simulation, config: ServerConfig(num_rounds=2, round_timeout=None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment on federated manner.\n",
      "FedAvg simulation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-02 10:28:47,448\tINFO worker.py:1553 -- Started a local Ray instance.\n",
      "INFO flwr 2023-05-02 10:28:48,043 | app.py:180 | Flower VCE: Ray initialized with resources: {'object_store_memory': 23141836800.0, 'GPU': 1.0, 'memory': 46283673600.0, 'CPU': 16.0, 'node:172.17.0.2': 1.0, 'accelerator_type:RTX': 1.0}\n",
      "INFO flwr 2023-05-02 10:28:48,044 | server.py:86 | Initializing global parameters\n",
      "INFO flwr 2023-05-02 10:28:48,044 | server.py:269 | Using initial parameters provided by strategy\n",
      "INFO flwr 2023-05-02 10:28:48,045 | server.py:88 | Evaluating initial parameters\n",
      "INFO flwr 2023-05-02 10:28:48,119 | server.py:91 | initial parameters (loss, other metrics): 0.07364347982406616, {'accuracy': 0.102}\n",
      "INFO flwr 2023-05-02 10:28:48,119 | server.py:101 | FL starting\n",
      "DEBUG flwr 2023-05-02 10:28:48,119 | server.py:218 | fit_round 1: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server-side evaluation loss 0.07364347982406616 / accuracy 0.102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2023-05-02 10:29:14,447 | server.py:232 | fit_round 1 received 10 results and 0 failures\n",
      "WARNING flwr 2023-05-02 10:29:14,459 | fedavg.py:243 | No fit_metrics_aggregation_fn provided\n",
      "INFO flwr 2023-05-02 10:29:14,534 | server.py:119 | fit progress: (1, 0.0641543595790863, {'accuracy': 0.304}, 26.41476331499871)\n",
      "DEBUG flwr 2023-05-02 10:29:14,535 | server.py:168 | evaluate_round 1: strategy sampled 5 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server-side evaluation loss 0.0641543595790863 / accuracy 0.304\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=1719203)\u001b[0m Accuracy 0.276\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=1719273)\u001b[0m Accuracy 0.304\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=1719380)\u001b[0m Accuracy 0.302\n",
      "\u001b[2m\u001b[1m\u001b[36m(autoscaler +40s)\u001b[0m Tip: use `ray status` to view detailed cluster status. To disable these messages, set RAY_SCHEDULER_EVENTS=0.\n",
      "\u001b[2m\u001b[1m\u001b[33m(autoscaler +40s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'GPU': 1.0, 'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=1719500)\u001b[0m Accuracy 0.302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2023-05-02 10:29:24,453 | server.py:182 | evaluate_round 1 received 5 results and 0 failures\n",
      "DEBUG flwr 2023-05-02 10:29:24,454 | server.py:218 | fit_round 2: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=1719622)\u001b[0m Accuracy 0.312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2023-05-02 10:29:50,923 | server.py:232 | fit_round 2 received 10 results and 0 failures\n",
      "INFO flwr 2023-05-02 10:29:51,009 | server.py:119 | fit progress: (2, 0.0557953782081604, {'accuracy': 0.344}, 62.889273521956056)\n",
      "DEBUG flwr 2023-05-02 10:29:51,009 | server.py:168 | evaluate_round 2: strategy sampled 5 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server-side evaluation loss 0.0557953782081604 / accuracy 0.344\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=1720938)\u001b[0m Accuracy 0.342\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=1721051)\u001b[0m Accuracy 0.344\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=1721162)\u001b[0m Accuracy 0.362\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=1721229)\u001b[0m Accuracy 0.364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2023-05-02 10:30:00,919 | server.py:182 | evaluate_round 2 received 5 results and 0 failures\n",
      "INFO flwr 2023-05-02 10:30:00,920 | server.py:147 | FL finished in 72.80058249994181\n",
      "INFO flwr 2023-05-02 10:30:00,920 | app.py:218 | app_fit: losses_distributed [(1, 0.06414921188354492), (2, 0.05606036233901977)]\n",
      "INFO flwr 2023-05-02 10:30:00,921 | app.py:219 | app_fit: metrics_distributed_fit {}\n",
      "INFO flwr 2023-05-02 10:30:00,921 | app.py:220 | app_fit: metrics_distributed {'accuracy': [(1, 0.2992), (2, 0.354)]}\n",
      "INFO flwr 2023-05-02 10:30:00,921 | app.py:221 | app_fit: losses_centralized [(0, 0.07364347982406616), (1, 0.0641543595790863), (2, 0.0557953782081604)]\n",
      "INFO flwr 2023-05-02 10:30:00,922 | app.py:222 | app_fit: metrics_centralized {'accuracy': [(0, 0.102), (1, 0.304), (2, 0.344)]}\n",
      "INFO flwr 2023-05-02 10:30:00,925 | app.py:146 | Starting Flower simulation, config: ServerConfig(num_rounds=2, round_timeout=None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FedAvgM simulation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-02 10:30:04,636\tINFO worker.py:1553 -- Started a local Ray instance.\n",
      "INFO flwr 2023-05-02 10:30:05,240 | app.py:180 | Flower VCE: Ray initialized with resources: {'object_store_memory': 22997648179.0, 'memory': 45995296359.0, 'accelerator_type:RTX': 1.0, 'node:172.17.0.2': 1.0, 'CPU': 16.0, 'GPU': 1.0}\n",
      "INFO flwr 2023-05-02 10:30:05,240 | server.py:86 | Initializing global parameters\n",
      "INFO flwr 2023-05-02 10:30:05,241 | server.py:269 | Using initial parameters provided by strategy\n",
      "INFO flwr 2023-05-02 10:30:05,241 | server.py:88 | Evaluating initial parameters\n",
      "INFO flwr 2023-05-02 10:30:05,308 | server.py:91 | initial parameters (loss, other metrics): 0.07371985340118409, {'accuracy': 0.096}\n",
      "INFO flwr 2023-05-02 10:30:05,308 | server.py:101 | FL starting\n",
      "DEBUG flwr 2023-05-02 10:30:05,309 | server.py:218 | fit_round 1: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server-side evaluation loss 0.07371985340118409 / accuracy 0.096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2023-05-02 10:30:31,777 | server.py:232 | fit_round 1 received 10 results and 0 failures\n",
      "WARNING flwr 2023-05-02 10:30:31,789 | fedavgm.py:214 | No fit_metrics_aggregation_fn provided\n",
      "INFO flwr 2023-05-02 10:30:31,857 | server.py:119 | fit progress: (1, 0.06301632738113404, {'accuracy': 0.292}, 26.548514598049223)\n",
      "DEBUG flwr 2023-05-02 10:30:31,858 | server.py:168 | evaluate_round 1: strategy sampled 5 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server-side evaluation loss 0.06301632738113404 / accuracy 0.292\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=1723962)\u001b[0m Accuracy 0.32\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=1724077)\u001b[0m Accuracy 0.322\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=1724196)\u001b[0m Accuracy 0.31\n",
      "\u001b[2m\u001b[1m\u001b[33m(autoscaler +1m57s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'GPU': 1.0, 'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=1724313)\u001b[0m Accuracy 0.292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2023-05-02 10:30:41,681 | server.py:182 | evaluate_round 1 received 5 results and 0 failures\n",
      "DEBUG flwr 2023-05-02 10:30:41,681 | server.py:218 | fit_round 2: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=1724429)\u001b[0m Accuracy 0.316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2023-05-02 10:31:08,057 | server.py:232 | fit_round 2 received 10 results and 0 failures\n",
      "INFO flwr 2023-05-02 10:31:08,142 | server.py:119 | fit progress: (2, 0.05581475305557251, {'accuracy': 0.352}, 62.83309047098737)\n",
      "DEBUG flwr 2023-05-02 10:31:08,142 | server.py:168 | evaluate_round 2: strategy sampled 5 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server-side evaluation loss 0.05581475305557251 / accuracy 0.352\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=1725693)\u001b[0m Accuracy 0.362\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=1725808)\u001b[0m Accuracy 0.352\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=1725922)\u001b[0m Accuracy 0.356\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=1726037)\u001b[0m Accuracy 0.352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2023-05-02 10:31:18,089 | server.py:182 | evaluate_round 2 received 5 results and 0 failures\n",
      "INFO flwr 2023-05-02 10:31:18,089 | server.py:147 | FL finished in 72.78040773805697\n",
      "INFO flwr 2023-05-02 10:31:18,090 | app.py:218 | app_fit: losses_distributed [(1, 0.06277724905014037), (2, 0.05550191216468812)]\n",
      "INFO flwr 2023-05-02 10:31:18,090 | app.py:219 | app_fit: metrics_distributed_fit {}\n",
      "INFO flwr 2023-05-02 10:31:18,090 | app.py:220 | app_fit: metrics_distributed {'accuracy': [(1, 0.312), (2, 0.35439999999999994)]}\n",
      "INFO flwr 2023-05-02 10:31:18,090 | app.py:221 | app_fit: losses_centralized [(0, 0.07371985340118409), (1, 0.06301632738113404), (2, 0.05581475305557251)]\n",
      "INFO flwr 2023-05-02 10:31:18,091 | app.py:222 | app_fit: metrics_centralized {'accuracy': [(0, 0.096), (1, 0.292), (2, 0.352)]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=1726157)\u001b[0m Accuracy 0.35\n"
     ]
    }
   ],
   "source": [
    "\n",
    "strategies = {\n",
    "    'FedAvg': fedavg,\n",
    "    'FedAvgM': fedavgM,\n",
    "    # 'QFedAvg': qfedavg,\n",
    "    # 'FaultTolerantFedAvg': ftfedavg,\n",
    "    # 'FedOpt': fedopt,\n",
    "    # 'FedProx': fedprox,\n",
    "    # 'FedAdagrad': fedadagrad,\n",
    "    # 'FedAdam': fedadam,\n",
    "    # 'FedYogi': fedyogi,\n",
    "}\n",
    "\n",
    "print(\"Experiment on federated manner.\")\n",
    "for sname, strategy in strategies.items():\n",
    "    print(f\"{sname} simulation\")\n",
    "\n",
    "    hist = fl.simulation.start_simulation(\n",
    "        client_fn=client_fn,\n",
    "        num_clients=NUM_CLIENTS,\n",
    "        config=fl.server.ServerConfig(num_rounds=EPOCH),\n",
    "        strategy=strategy,\n",
    "        client_resources=client_resources,\n",
    "    )\n",
    "\n",
    "    df_result = pd.DataFrame()\n",
    "    df_result['round'] = [i for i in range(1, EPOCH + 1)]\n",
    "    df_result['strategy'] = sname\n",
    "\n",
    "    # centralized metrics\n",
    "    metrics_cen = list(hist.metrics_centralized.keys())\n",
    "    metrics_dis = list(hist.metrics_distributed.keys())\n",
    "\n",
    "    for metric in metrics_cen:\n",
    "        df_result[f\"c_{metric}\"] = [h[1] for h in hist.metrics_centralized[metric][1:]]\n",
    "    for metric in metrics_dis:\n",
    "        df_result[f\"d_{metric}\"] = [h[1] for h in hist.metrics_distributed[metric]]\n",
    "\n",
    "    df_final = pd.concat([df_final, df_result], axis=0)\n",
    "\n",
    "df_final.to_csv('./result/result.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
