{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "S8KbmwmJNvpu",
        "xkFq4GuQ-W3c",
        "2Ycgu5y4kkHX"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Reference\n",
        "\n",
        "[Flower-1-intro-to-FL-Pytorch](https://colab.research.google.com/github/adap/flower/blob/main/doc/source/tutorial/Flower-1-Intro-to-FL-PyTorch.ipynb#scrollTo=lA9tsoNz9OT7)"
      ],
      "metadata": {
        "id": "-Vfdqc9XA1Ao"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "So1gACpd2n3X",
        "outputId": "2f3c6626-0d26-44d6-d5cb-bf7ba483be12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Installing dependencies"
      ],
      "metadata": {
        "id": "HpA3J5aPuKPk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q flwr[simulation]\n",
        "!pip install -U kaleido     # for using plotly library"
      ],
      "metadata": {
        "id": "NExfB-CjuNCe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75ddaab3-3d83-40e1-aa0e-dec603112d31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: kaleido in /usr/local/lib/python3.10/dist-packages (0.2.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x234FB-1tRc-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11ac9005-bf1c-4b1d-9ff6-aec6e089cffa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on cuda using PyTorch 2.0.0+cu118 and Flower 1.4.0\n"
          ]
        }
      ],
      "source": [
        "from collections import OrderedDict\n",
        "from typing import List, Tuple, Dict, Optional\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "import math\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.init as init\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, random_split, TensorDataset\n",
        "from torchvision.datasets import CIFAR10\n",
        "\n",
        "import flwr as fl\n",
        "from flwr.common import Metrics\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\n",
        "    f\"Training on {DEVICE} using PyTorch {torch.__version__} and Flower {fl.__version__}\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Utils"
      ],
      "metadata": {
        "id": "S8KbmwmJNvpu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_mean_and_std(dataset):\n",
        "    '''Compute the mean and std value of dataset.'''\n",
        "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=True, num_workers=2)\n",
        "    mean = torch.zeros(3)\n",
        "    std = torch.zeros(3)\n",
        "    print('==> Computing mean and std..')\n",
        "    for inputs, targets in dataloader:\n",
        "        for i in range(3):\n",
        "            mean[i] += inputs[:,i,:,:].mean()\n",
        "            std[i] += inputs[:,i,:,:].std()\n",
        "    mean.div_(len(dataset))\n",
        "    std.div_(len(dataset))\n",
        "    return mean, std\n",
        "\n",
        "def init_params(net):\n",
        "    '''Init layer parameters.'''\n",
        "    for m in net.modules():\n",
        "        if isinstance(m, nn.Conv2d):\n",
        "            init.kaiming_normal(m.weight, mode='fan_out')\n",
        "            if m.bias:\n",
        "                init.constant(m.bias, 0)\n",
        "        elif isinstance(m, nn.BatchNorm2d):\n",
        "            init.constant(m.weight, 1)\n",
        "            init.constant(m.bias, 0)\n",
        "        elif isinstance(m, nn.Linear):\n",
        "            init.normal(m.weight, std=1e-3)\n",
        "            if m.bias:\n",
        "                init.constant(m.bias, 0)"
      ],
      "metadata": {
        "id": "SaqsTSDRNxC_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading the data"
      ],
      "metadata": {
        "id": "xkFq4GuQ-W3c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CLASSES = (\n",
        "    \"plane\",\n",
        "    \"car\",\n",
        "    \"bird\",\n",
        "    \"cat\",\n",
        "    \"deer\",\n",
        "    \"dog\",\n",
        "    \"frog\",\n",
        "    \"horse\",\n",
        "    \"ship\",\n",
        "    \"truck\",\n",
        ")"
      ],
      "metadata": {
        "id": "9KBP0fxE-Vs0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_CLIENTS = 10\n",
        "BATCH_SIZE = 128"
      ],
      "metadata": {
        "id": "t4NP8fhD-lsY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_datasets(divide=True):\n",
        "    # Download and transform CIFAR-10 (train and test)\n",
        "\n",
        "    transform_train = transforms.Compose([\n",
        "        transforms.RandomCrop(32, padding=4),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "    ])\n",
        "\n",
        "    transform_test = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "    ])\n",
        "\n",
        "    trainset = CIFAR10(\"./dataset\", train=True, download=True, transform=transform_train)\n",
        "    testset = CIFAR10(\"./dataset\", train=False, download=True, transform=transform_test)\n",
        "\n",
        "    # Split training set into 10 partitions to simulate the individual dataset\n",
        "    partition_size = len(trainset) // NUM_CLIENTS\n",
        "    lengths = [partition_size] * NUM_CLIENTS\n",
        "    datasets = random_split(trainset, lengths, torch.Generator().manual_seed(42))\n",
        "\n",
        "    # Split each partition into train/val and create DataLoader\n",
        "    trainloaders = []\n",
        "    valloaders = []\n",
        "    if divide:\n",
        "        for ds in datasets:\n",
        "            len_val = len(ds) // 10     # 10 % validation set\n",
        "            len_train = len(ds) - len_val\n",
        "            lengths = [len_train, len_val]\n",
        "            ds_train, ds_val = random_split(ds, lengths, torch.Generator().manual_seed(42))\n",
        "            trainloaders.append(DataLoader(ds_train, batch_size=BATCH_SIZE, shuffle=True))\n",
        "            valloaders.append(DataLoader(ds_val, batch_size=BATCH_SIZE))\n",
        "    else:\n",
        "        trainloaders.append(DataLoader(trainset, batch_size=128, shuffle=True))\n",
        "    testloader = DataLoader(testset, batch_size=BATCH_SIZE)\n",
        "    return trainloaders, valloaders, testloader\n",
        "\n",
        "trainloaders, valloaders, testloader = load_datasets(divide=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5EbUiOGh-rWx",
        "outputId": "5cf65b09-46e2-48bc-c992-c079480ca633"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./dataset/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:13<00:00, 13070429.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./dataset/cifar-10-python.tar.gz to ./dataset\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Take a look at the first batch of images and labels in the first training set (i.e., trainloaders[0]) before we move on."
      ],
      "metadata": {
        "id": "z-skjIVJ_0pc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "images, labels = next(iter(trainloaders[0]))\n",
        "\n",
        "# Reshape and convert images to a NumPy array\n",
        "# matplotlib requires images with the shape (hight, width, 3)\n",
        "images = images.permute(0, 2, 3, 1).numpy()\n",
        "# Denormalize\n",
        "images = images / 2 + 0.5\n",
        "\n",
        "# Create a figure and a grid of subplots\n",
        "fig, axs = plt.subplots(4, 8, figsize=(12, 6))\n",
        "\n",
        "# Loop over the images and plot them\n",
        "for i, ax in enumerate(axs.flat):\n",
        "    ax.imshow(images[i])\n",
        "    ax.set_title(CLASSES[labels[i]])\n",
        "    ax.axis(\"off\")\n",
        "\n",
        "# Show the plot\n",
        "fig.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "nwBBv_xr_8it"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 1: Centralized Training with PyTorch"
      ],
      "metadata": {
        "id": "F0lPsARpAuqe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Resnet-50\n",
        "[github](https://github.com/kuangliu/pytorch-cifar/blob/master/models/resnet.py)"
      ],
      "metadata": {
        "id": "2Ycgu5y4kkHX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Resnet-18\n",
        "# https://github.com/kuangliu/pytorch-cifar/blob/master/models/resnet.py\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "    \n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(\n",
        "            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
        "                               stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion*planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion*planes,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(self.expansion*planes)\n",
        "            )\n",
        "        \n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
        "                               stride=stride, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.conv3 = nn.Conv2d(planes, self.expansion *\n",
        "                               planes, kernel_size=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion*planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion*planes,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(self.expansion*planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = F.relu(self.bn2(self.conv2(out)))\n",
        "        out = self.bn3(self.conv3(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, num_blocks, num_classes=10):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_planes=64\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3,\n",
        "                               stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
        "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
        "        self.linear = nn.Linear(512*block.expansion, num_classes)\n",
        "\n",
        "    def _make_layer(self, block, planes, num_blocks, stride):\n",
        "        strides = [stride] + [1] * (num_blocks-1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_planes, planes, stride))\n",
        "            self.in_planes = planes * block.expansion\n",
        "        return nn.Sequential(*layers)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = F.avg_pool2d(out, 4)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "        return out\n",
        "\n",
        "def ResNet18():\n",
        "    return ResNet(BasicBlock, [2, 2, 2, 2])\n",
        "\n",
        "def ResNet50():\n",
        "    return ResNet(Bottleneck, [3, 4, 6, 3])\n"
      ],
      "metadata": {
        "id": "l238MQnPiewB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "9GgH5VGIFTk8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train configuration\n"
      ],
      "metadata": {
        "id": "gTnxTPPjMQGi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "net = ResNet50().to(DEVICE)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.01,\n",
        "                      momentum=0.9, weight_decay=5e-4)\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)"
      ],
      "metadata": {
        "id": "ZjwxkNs9Q9Lf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training and test functions"
      ],
      "metadata": {
        "id": "pPRCVl2_5Qbw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(net, trainloader):\n",
        "    \"\"\"Train the network on the training set.\"\"\"\n",
        "    net.train()\n",
        "    train_loss, correct, total = 0, 0, 0\n",
        "\n",
        "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
        "        inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += targets.size(0)\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "    train_loss /= len(trainloader.dataset)\n",
        "    accuracy = correct / total\n",
        "\n",
        "    return train_loss, accuracy\n",
        "\n",
        "\n",
        "def test(net, testloader):\n",
        "    \"\"\"Evaluate the network on the entire test set.\"\"\"\n",
        "    net.eval()\n",
        "    test_loss, correct, total = 0, 0, 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
        "            inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "            test_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "    \n",
        "    test_loss /= len(testloader)\n",
        "    accuracy = correct / total\n",
        "\n",
        "    return test_loss, accuracy"
      ],
      "metadata": {
        "id": "kBdcf1M95UFo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training the model"
      ],
      "metadata": {
        "id": "H_GpVfSo7tHX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "save_path = \"/content/drive/MyDrive/working/checkpoint/best_ckpt.pth\"\n",
        "\n",
        "trainloader = trainloaders[0]\n",
        "#valloader = valloaders[0]\n",
        "#net = ResNet50().to(DEVICE)\n",
        "\n",
        "best_acc = 0\n",
        "for epoch in range(1, 1001):\n",
        "    train_loss, _ = train(net, trainloader)\n",
        "    test_loss, accuracy = test(net, testloader)\n",
        "    scheduler.step()\n",
        "    if epoch % 10 == 0:\n",
        "        print(f\"Epoch {epoch}: validation loss {test_loss}, accuracy {accuracy}\")\n",
        "    if best_acc < accuracy:\n",
        "        print(f'Saving...(epoch {epoch})')\n",
        "\n",
        "        state = {\n",
        "            'net': net.state_dict(),\n",
        "            'acc': accuracy,\n",
        "            'epoch': epoch,\n",
        "        }\n",
        "        torch.save(state, save_path)\n",
        "        best_acc = accuracy\n",
        "        \n",
        "\n",
        "loss, accuracy = test(net, testloader)\n",
        "print(f\"Final test set performance:\\n\\tloss {loss}\\n\\taccuracy {accuracy}\")"
      ],
      "metadata": {
        "id": "Ct8ZcuVe7u6v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = torch.load(save_path)\n",
        "\n",
        "net = ResNet50().to(DEVICE)\n",
        "net.load_state_dict(best_model['net'])\n",
        "\n",
        "loss, accuracy = test(net, testloader)\n",
        "print(f\"Final test set performance:\\n\\tloss {loss}\\n\\taccuracy {accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Huy3XghlgCwk",
        "outputId": "c982132e-23ba-43d1-8904-2de11bd57b21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final test set performance:\n",
            "\tloss 0.25099298034947887\n",
            "\taccuracy 0.9495\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2 : Federated Learning with Flower"
      ],
      "metadata": {
        "id": "uGaV0t-G8Ity"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Config"
      ],
      "metadata": {
        "id": "Q1D17MLAAp3T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# General\n",
        "NUM_CLIENTS = 10\n",
        "BATCH_SIZE = 128"
      ],
      "metadata": {
        "id": "63n_nB-GArdK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Make well-balanced dataset for FL clients"
      ],
      "metadata": {
        "id": "MuNP1bnohfPc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "trainset = CIFAR10(\"./dataset\", train=True, download=True, transform=transform_train)\n",
        "testset = CIFAR10(\"./dataset\", train=False, download=True, transform=transform_test)\n",
        "\n",
        "print(len(trainset), len(testset))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7qxQX2gInrQU",
        "outputId": "f4a7b2f2-2090-4ef8-aa2c-7b470e672312"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "50000 10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "li_trainset = [torch.empty([0, 3, 32, 32]) for _ in range(10)]\n",
        "labels = [[] for _ in range(10)]\n",
        "\n",
        "for x, label in trainset:\n",
        "    labels[label].append(label)\n",
        "    li_trainset[label] = torch.cat((li_trainset[label], x[None, :]), dim=0)\n",
        "    \n",
        "labels = [torch.tensor(x) for x in labels]"
      ],
      "metadata": {
        "id": "b6xIKD-CovZB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d_train = [torch.empty([0, 3, 32, 32]) for _ in range(NUM_CLIENTS)]\n",
        "d_train_labels = [torch.tensor([], dtype=int) for _ in range(NUM_CLIENTS)]\n",
        "ds_clients = []         # dataset for each client\n",
        "dl_clients = []         # dataloader for each client\n",
        "\n",
        "\n",
        "for ds, label in zip(li_trainset, labels):\n",
        "    indices = torch.randperm(5000)\n",
        "    ds = ds[indices]\n",
        "    label = label[indices]\n",
        "    num_data = 5000 // NUM_CLIENTS\n",
        "    for i in range(NUM_CLIENTS):\n",
        "        d_train[i] = torch.cat((d_train[i], ds[i*num_data : (i+1)*num_data]), dim=0)\n",
        "        d_train_labels[i] = torch.cat((d_train_labels[i], label[i*num_data : (i+1)*num_data]))\n",
        "\n",
        "for i in range(NUM_CLIENTS):\n",
        "    indices = torch.randperm(5000)\n",
        "    d_train[i] = d_train[i][indices]\n",
        "    d_train_labels[i] = d_train_labels[i][indices]\n",
        "    ds_client = TensorDataset(d_train[i], d_train_labels[i])\n",
        "    dl_client = DataLoader(\n",
        "        ds_client,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle=True,\n",
        "    )\n",
        "    ds_clients.append(ds_client)\n",
        "    dl_clients.append(dl_client)\n",
        "\n",
        "testloader = DataLoader(\n",
        "    testset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,\n",
        ")\n",
        "\n",
        "print(len(ds_clients[0]), len(dl_clients[0]))"
      ],
      "metadata": {
        "id": "MsHufFHuy0PO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc48565b-1ea0-40f2-b674-2b096eeb0c17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5000 40\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train/Test function"
      ],
      "metadata": {
        "id": "xoAagMJFCOMC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(net, trainloader, epochs=1):\n",
        "    \"\"\"Train the network on the training set.\"\"\"\n",
        "    net.train()\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.SGD(net.parameters(), lr=0.01,\n",
        "                        momentum=0.9, weight_decay=5e-4)\n",
        "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "\n",
        "        for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
        "            inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "        scheduler.step()\n",
        "\n",
        "\n",
        "def test(net, testloader):\n",
        "    \"\"\"Evaluate the network on the entire test set.\"\"\"\n",
        "    \n",
        "    net.eval()\n",
        "    test_loss, correct, total = 0, 0, 0\n",
        "    \n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
        "            inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "            test_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "    \n",
        "    test_loss /= len(testloader)\n",
        "    accuracy = correct / total\n",
        "\n",
        "    return test_loss, accuracy"
      ],
      "metadata": {
        "id": "n42uW_eMCP6E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Updating model parameters"
      ],
      "metadata": {
        "id": "o6SAFDr78LrC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# def get_parameters(net) -> List[np.ndarray]:\n",
        "#     return [val.cpu().numpy() for _, val in net.state_dict().items()]\n",
        "\n",
        "# def set_parameters(net, parameters: List[np.ndarray]):\n",
        "#     params_dict = zip(net.state_dict().keys(), parameters)\n",
        "#     state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n",
        "#     net.load_state_dict(state_dict, strict=True)\n",
        "\n",
        "\n",
        "def get_parameters(net) -> List[np.ndarray]:\n",
        "    return [val.cpu().numpy() for _, val in net.state_dict().items()]\n",
        "\n",
        "def set_parameters(net, parameters: List[np.ndarray]):\n",
        "    print(f\"Net: {len(net.state_dict().keys())} Params: {len(parameters)}\")\n",
        "    params_dict = zip(net.state_dict().keys(), parameters)\n",
        "    for k, v in params_dict:\n",
        "        continue\n",
        "    state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n",
        "    net.load_state_dict(state_dict, strict=False)"
      ],
      "metadata": {
        "id": "pMUxzers8NU6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implementing a Flower client"
      ],
      "metadata": {
        "id": "iET4g1U88t4m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FlowerClient(fl.client.NumPyClient):\n",
        "    def __init__(self, net, trainloader, valloader):\n",
        "        self.net = net\n",
        "        self.trainloader = trainloader\n",
        "        self.valloader = valloader\n",
        "    \n",
        "    def get_parameters(self, config):\n",
        "        return get_parameters(self.net)\n",
        "\n",
        "    def fit(self, parameters, config):\n",
        "        set_parameters(self.net, parameters)\n",
        "        train(self.net, self.trainloader, epochs=1)\n",
        "        return get_parameters(self.net), len(self.trainloader), {}\n",
        "    \n",
        "    def evaluate(self, parameters, config):\n",
        "        set_parameters(self.net, parameters)\n",
        "        loss, accuracy = test(self.net, self.valloader)\n",
        "        return float(loss), len(self.valloader), {\"accuracy\": float(accuracy)}\n"
      ],
      "metadata": {
        "id": "bYIyDQTc8zW1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using the Virtual Client Engine"
      ],
      "metadata": {
        "id": "XKO6jC9u9Vp5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def client_fn(cid: str) -> FlowerClient:\n",
        "    \"\"\"Create a Flower client representing a single organization.\"\"\"\n",
        "\n",
        "    # Load model\n",
        "    #net = Net().to(DEVICE)\n",
        "    net = ResNet50().to(DEVICE)\n",
        "\n",
        "    # Load data (CIFAR-10)\n",
        "    # Note: each client gets a different trainloader/valloader, so each client \n",
        "    # will train and evaluate on their own unique data\n",
        "    trainloader = dl_clients[int(cid)]\n",
        "    #valloader = valloaders[int(cid)]\n",
        "    valloader = testloader\n",
        "\n",
        "    # Create a single Flower client representing a single organization\n",
        "    return FlowerClient(net, trainloader, valloader)"
      ],
      "metadata": {
        "id": "0F-F_ltw9UWZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluate global model"
      ],
      "metadata": {
        "id": "Ybq8tUOOQiWn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(\n",
        "    server_round: int, parameters: fl.common.NDArrays, config: Dict[str, fl.common.Scalar]\n",
        ") -> Optional[Tuple[float, Dict[str, fl.common.Scalar]]]:\n",
        "\n",
        "    #net = Net()\n",
        "    net = ResNet50().to(DEVICE)\n",
        "    set_parameters(net, parameters)\n",
        "    net = net.to(DEVICE)\n",
        "    loss, accuracy = test(net, testloader)\n",
        "    \n",
        "    return loss, {\"loss\": loss, \"accuracy\": accuracy} # The return type must be (loss, metric tuple) form"
      ],
      "metadata": {
        "id": "CvNSTVgtQvnA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Aggregate evaluation of local model"
      ],
      "metadata": {
        "id": "d6l4U_dkCUnY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def weighted_average(metrics: List[Tuple[int, Metrics]]) -> Metrics:\n",
        "    # Multiply accuracy of each client by number of examples used\n",
        "    accuracies = [num_examples * m[\"accuracy\"] for num_examples, m in metrics]\n",
        "    examples = [num_examples for num_examples, _ in metrics]\n",
        "    \n",
        "    # Aggregate and return custom metric (weighted average)\n",
        "    return {\"accuracy\": sum(accuracies) / sum(examples)}"
      ],
      "metadata": {
        "id": "7FgrfabPCWwp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create FL strategy"
      ],
      "metadata": {
        "id": "ED5wYI0_Y-Ta"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create FedAvg strategy\n",
        "strategy = fl.server.strategy.FedAvg(\n",
        "    fraction_fit=1.0,\n",
        "    fraction_evaluate=0.5,\n",
        "    min_fit_clients=10,\n",
        "    min_evaluate_clients=5,\n",
        "    min_available_clients=10,\n",
        "    evaluate_metrics_aggregation_fn=weighted_average,   # aggregate evaluation of local model\n",
        "    evaluate_fn=evaluate,   # evaluate global model\n",
        "    #initial_parameters=fl.common.ndarrays_to_parameters(get_parameters(ResNet50())),\n",
        ")"
      ],
      "metadata": {
        "id": "JqC_oyI8ZCpG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## FL simulation"
      ],
      "metadata": {
        "id": "vjS94lE7ZE-G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### simulation parameters"
      ],
      "metadata": {
        "id": "wKJShJtxZHRP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_rounds = 5\n",
        "\n",
        "# Specify client resources if you need GPU (defaults to 1 CPU and 0 GPU)\n",
        "client_resources = None\n",
        "if DEVICE.type == \"cuda\":\n",
        "    client_resources = {\"num_gpus\": 1}"
      ],
      "metadata": {
        "id": "KSfafyrzZKSn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Simulate"
      ],
      "metadata": {
        "id": "ql5d0c_xZPYf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Start simulation\n",
        "hist = fl.simulation.start_simulation(\n",
        "    client_fn=client_fn,\n",
        "    num_clients=NUM_CLIENTS,\n",
        "    config=fl.server.ServerConfig(num_rounds=num_rounds),\n",
        "    strategy=strategy,\n",
        "    client_resources=client_resources,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XR3BQS9mCu7t",
        "outputId": "a6e03cf1-1400-499d-f667-d4eb5e0bc2f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO flwr 2023-04-29 14:55:54,248 | app.py:146 | Starting Flower simulation, config: ServerConfig(num_rounds=5, round_timeout=None)\n",
            "INFO:flwr:Starting Flower simulation, config: ServerConfig(num_rounds=5, round_timeout=None)\n",
            "2023-04-29 14:55:57,701\tINFO worker.py:1625 -- Started a local Ray instance.\n",
            "INFO flwr 2023-04-29 14:56:00,226 | app.py:180 | Flower VCE: Ray initialized with resources: {'GPU': 1.0, 'memory': 7984145204.0, 'node:172.28.0.12': 1.0, 'CPU': 2.0, 'object_store_memory': 3992072601.0}\n",
            "INFO:flwr:Flower VCE: Ray initialized with resources: {'GPU': 1.0, 'memory': 7984145204.0, 'node:172.28.0.12': 1.0, 'CPU': 2.0, 'object_store_memory': 3992072601.0}\n",
            "INFO flwr 2023-04-29 14:56:00,235 | server.py:86 | Initializing global parameters\n",
            "INFO:flwr:Initializing global parameters\n",
            "INFO flwr 2023-04-29 14:56:00,240 | server.py:273 | Requesting initial parameters from one random client\n",
            "INFO:flwr:Requesting initial parameters from one random client\n",
            "\u001b[2m\u001b[36m(pid=12167)\u001b[0m 2023-04-29 14:56:04.014431: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "INFO flwr 2023-04-29 14:56:08,612 | server.py:277 | Received initial parameters from one random client\n",
            "INFO:flwr:Received initial parameters from one random client\n",
            "INFO flwr 2023-04-29 14:56:08,616 | server.py:88 | Evaluating initial parameters\n",
            "INFO:flwr:Evaluating initial parameters\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Net: 320 Params: 320\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO flwr 2023-04-29 14:56:35,656 | server.py:91 | initial parameters (loss, other metrics): 2.3024764604206327, {'loss': 2.3024764604206327, 'accuracy': 0.1}\n",
            "INFO:flwr:initial parameters (loss, other metrics): 2.3024764604206327, {'loss': 2.3024764604206327, 'accuracy': 0.1}\n",
            "INFO flwr 2023-04-29 14:56:35,662 | server.py:101 | FL starting\n",
            "INFO:flwr:FL starting\n",
            "DEBUG flwr 2023-04-29 14:56:35,669 | server.py:218 | fit_round 1: strategy sampled 10 clients (out of 10)\n",
            "DEBUG:flwr:fit_round 1: strategy sampled 10 clients (out of 10)\n",
            "ERROR flwr 2023-04-29 14:56:45,618 | ray_client_proxy.py:87 | Task was killed due to the node running low on memory.\n",
            "Memory on the node (IP: 172.28.0.12, ID: bf6ae768a6470a8231a5e3650551b456dfddfd25b3f425cc28bfeb42) where the task (task ID: 4ac8c90a0f59aee34a53c97349b91cdf508af74301000000, name=launch_and_fit, pid=12387, memory used=0.05GB) was running was 12.06GB / 12.68GB (0.95118), which exceeds the memory usage threshold of 0.95. Ray killed this worker (ID: 573894a2c97bca9d9523985e671763ec49d477f39747c7e451cffa43) because it was the most recently scheduled task; to see more information about memory usage on this node, use `ray logs raylet.out -ip 172.28.0.12`. To see the logs of the worker, use `ray logs worker-573894a2c97bca9d9523985e671763ec49d477f39747c7e451cffa43*out -ip 172.28.0.12. Top 10 memory users:\n",
            "PID\tMEM(GB)\tCOMMAND\n",
            "8692\t10.41\t/usr/bin/python3 -m ipykernel_launcher -f /root/.local/share/jupyter/runtime/kernel-4cbabbf3-e3cb-4f...\n",
            "107\t0.10\t/usr/bin/python3 /usr/local/bin/jupyter-notebook --debug --transport=\"ipc\" --ip=172.28.0.12 --Notebo...\n",
            "12028\t0.06\t/usr/bin/python3 -u /usr/local/lib/python3.10/dist-packages/ray/dashboard/agent.py --node-ip-address...\n",
            "12387\t0.05\tray::IDLE\n",
            "964\t0.05\t/opt/google/drive/drive --features=fuse_max_background:1000,max_read_qps:1000,max_write_qps:1000,max...\n",
            "11940\t0.05\t/usr/bin/python3 /usr/local/lib/python3.10/dist-packages/ray/dashboard/dashboard.py --host=127.0.0.1...\n",
            "7\t0.04\t/tools/node/bin/node /datalab/web/app.js\n",
            "11922\t0.04\t/usr/bin/python3 -u /usr/local/lib/python3.10/dist-packages/ray/autoscaler/_private/monitor.py --log...\n",
            "12014\t0.04\t/usr/bin/python3 -u /usr/local/lib/python3.10/dist-packages/ray/_private/log_monitor.py --logs-dir=/...\n",
            "58\t0.03\tpython3 /usr/local/bin/colab-fileshim.py\n",
            "Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n",
            "ERROR:flwr:Task was killed due to the node running low on memory.\n",
            "Memory on the node (IP: 172.28.0.12, ID: bf6ae768a6470a8231a5e3650551b456dfddfd25b3f425cc28bfeb42) where the task (task ID: 4ac8c90a0f59aee34a53c97349b91cdf508af74301000000, name=launch_and_fit, pid=12387, memory used=0.05GB) was running was 12.06GB / 12.68GB (0.95118), which exceeds the memory usage threshold of 0.95. Ray killed this worker (ID: 573894a2c97bca9d9523985e671763ec49d477f39747c7e451cffa43) because it was the most recently scheduled task; to see more information about memory usage on this node, use `ray logs raylet.out -ip 172.28.0.12`. To see the logs of the worker, use `ray logs worker-573894a2c97bca9d9523985e671763ec49d477f39747c7e451cffa43*out -ip 172.28.0.12. Top 10 memory users:\n",
            "PID\tMEM(GB)\tCOMMAND\n",
            "8692\t10.41\t/usr/bin/python3 -m ipykernel_launcher -f /root/.local/share/jupyter/runtime/kernel-4cbabbf3-e3cb-4f...\n",
            "107\t0.10\t/usr/bin/python3 /usr/local/bin/jupyter-notebook --debug --transport=\"ipc\" --ip=172.28.0.12 --Notebo...\n",
            "12028\t0.06\t/usr/bin/python3 -u /usr/local/lib/python3.10/dist-packages/ray/dashboard/agent.py --node-ip-address...\n",
            "12387\t0.05\tray::IDLE\n",
            "964\t0.05\t/opt/google/drive/drive --features=fuse_max_background:1000,max_read_qps:1000,max_write_qps:1000,max...\n",
            "11940\t0.05\t/usr/bin/python3 /usr/local/lib/python3.10/dist-packages/ray/dashboard/dashboard.py --host=127.0.0.1...\n",
            "7\t0.04\t/tools/node/bin/node /datalab/web/app.js\n",
            "11922\t0.04\t/usr/bin/python3 -u /usr/local/lib/python3.10/dist-packages/ray/autoscaler/_private/monitor.py --log...\n",
            "12014\t0.04\t/usr/bin/python3 -u /usr/local/lib/python3.10/dist-packages/ray/_private/log_monitor.py --logs-dir=/...\n",
            "58\t0.03\tpython3 /usr/local/bin/colab-fileshim.py\n",
            "Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[1m\u001b[36m(autoscaler +10m27s)\u001b[0m Tip: use `ray status` to view detailed cluster status. To disable these messages, set RAY_SCHEDULER_EVENTS=0.\n",
            "\u001b[2m\u001b[1m\u001b[33m(autoscaler +10m27s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'GPU': 1.0, 'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "metrics = list(hist.metrics_centralized.keys())\n",
        "\n",
        "df_result = pd.DataFrame(\n",
        "    columns=metrics,\n",
        ")\n",
        "df_result['round'] = [i for i in range(num_rounds + 1)]\n",
        "\n",
        "for metric in metrics:\n",
        "    df_result[metric] = [h[1] for h in hist.metrics_centralized[metric]]\n",
        "\n",
        "print(df_result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_123rXXVZwqL",
        "outputId": "82b549f0-81a6-4e2d-d899-2bd10c0810e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       loss  accuracy  round\n",
            "0  0.072119    0.1000      0\n",
            "1  0.061667    0.3069      1\n",
            "2  0.053220    0.3809      2\n",
            "3  0.049600    0.4196      3\n",
            "4  0.047812    0.4447      4\n",
            "5  0.046144    0.4649      5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Plot the result graphs"
      ],
      "metadata": {
        "id": "u_kbKC2Beao-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.graph_objects as go"
      ],
      "metadata": {
        "id": "hljaU7HJfEY2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "round-loss"
      ],
      "metadata": {
        "id": "YBzRBSloemdh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_result['accuracy'].values)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t7rhw23Ngw7K",
        "outputId": "6888ecd0-7e7c-4891-f68f-882dcec52198"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.1    0.3069 0.3809 0.4196 0.4447 0.4649]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig = go.Figure()\n",
        "# Create and style traces\n",
        "fig.add_trace(\n",
        "    go.Scatter(\n",
        "        x=df_result['round'].values[1:],\n",
        "        y=df_result['loss'].values[1:],\n",
        "    )\n",
        ")\n",
        "\n",
        "fig.update_layout(\n",
        "    title=\"\",\n",
        "    xaxis_title=\"round\",\n",
        "    yaxis_title=\"loss\",\n",
        "    #plot_bgcolor=\"rgba(0,0,0,0)\",\n",
        ")\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "o6JIz7kMeoki",
        "outputId": "53ff3884-30f1-457c-8c6b-11970662a947"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.18.2.min.js\"></script>                <div id=\"6eec7092-9e84-4155-acf3-8e9d8092f034\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"6eec7092-9e84-4155-acf3-8e9d8092f034\")) {                    Plotly.newPlot(                        \"6eec7092-9e84-4155-acf3-8e9d8092f034\",                        [{\"x\":[1,2,3,4,5],\"y\":[0.06166734161376953,0.053219888293743134,0.04960033710002899,0.047812195229530334,0.04614442213773728],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"title\":{\"text\":\"\"},\"xaxis\":{\"title\":{\"text\":\"round\"}},\"yaxis\":{\"title\":{\"text\":\"loss\"}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('6eec7092-9e84-4155-acf3-8e9d8092f034');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}