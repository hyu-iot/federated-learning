{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Vfdqc9XA1Ao"
      },
      "source": [
        "# Reference\n",
        "\n",
        "[Flower-1-intro-to-FL-Pytorch](https://colab.research.google.com/github/adap/flower/blob/main/doc/source/tutorial/Flower-1-Intro-to-FL-PyTorch.ipynb#scrollTo=lA9tsoNz9OT7)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HpA3J5aPuKPk"
      },
      "source": [
        "\n",
        "# Installing dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x234FB-1tRc-",
        "outputId": "11ac9005-bf1c-4b1d-9ff6-aec6e089cffa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training on cuda:0 using PyTorch 2.0.0+cu117 and Flower 1.4.0\n"
          ]
        }
      ],
      "source": [
        "from collections import OrderedDict\n",
        "from typing import List, Tuple, Dict, Optional\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "import math\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.init as init\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, random_split, TensorDataset\n",
        "from torchvision.datasets import CIFAR10\n",
        "\n",
        "import flwr as fl\n",
        "from flwr.common import Metrics\n",
        "\n",
        "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\n",
        "    f\"Training on {DEVICE} using PyTorch {torch.__version__} and Flower {fl.__version__}\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S8KbmwmJNvpu"
      },
      "source": [
        "# Utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "SaqsTSDRNxC_"
      },
      "outputs": [],
      "source": [
        "def get_mean_and_std(dataset):\n",
        "    '''Compute the mean and std value of dataset.'''\n",
        "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=True, num_workers=2)\n",
        "    mean = torch.zeros(3)\n",
        "    std = torch.zeros(3)\n",
        "    print('==> Computing mean and std..')\n",
        "    for inputs, targets in dataloader:\n",
        "        for i in range(3):\n",
        "            mean[i] += inputs[:,i,:,:].mean()\n",
        "            std[i] += inputs[:,i,:,:].std()\n",
        "    mean.div_(len(dataset))\n",
        "    std.div_(len(dataset))\n",
        "    return mean, std\n",
        "\n",
        "def init_params(net):\n",
        "    '''Init layer parameters.'''\n",
        "    for m in net.modules():\n",
        "        if isinstance(m, nn.Conv2d):\n",
        "            init.kaiming_normal(m.weight, mode='fan_out')\n",
        "            if m.bias:\n",
        "                init.constant(m.bias, 0)\n",
        "        elif isinstance(m, nn.BatchNorm2d):\n",
        "            init.constant(m.weight, 1)\n",
        "            init.constant(m.bias, 0)\n",
        "        elif isinstance(m, nn.Linear):\n",
        "            init.normal(m.weight, std=1e-3)\n",
        "            if m.bias:\n",
        "                init.constant(m.bias, 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xkFq4GuQ-W3c"
      },
      "source": [
        "# Loading the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "9KBP0fxE-Vs0"
      },
      "outputs": [],
      "source": [
        "CLASSES = (\n",
        "    \"plane\",\n",
        "    \"car\",\n",
        "    \"bird\",\n",
        "    \"cat\",\n",
        "    \"deer\",\n",
        "    \"dog\",\n",
        "    \"frog\",\n",
        "    \"horse\",\n",
        "    \"ship\",\n",
        "    \"truck\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "t4NP8fhD-lsY"
      },
      "outputs": [],
      "source": [
        "NUM_CLIENTS = 10\n",
        "BATCH_SIZE = 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5EbUiOGh-rWx",
        "outputId": "5cf65b09-46e2-48bc-c992-c079480ca633"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "def load_datasets(divide=True):\n",
        "    # Download and transform CIFAR-10 (train and test)\n",
        "\n",
        "    transform_train = transforms.Compose([\n",
        "        transforms.RandomCrop(32, padding=4),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "    ])\n",
        "\n",
        "    transform_test = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "    ])\n",
        "\n",
        "    trainset = CIFAR10(\"./dataset\", train=True, download=True, transform=transform_train)\n",
        "    testset = CIFAR10(\"./dataset\", train=False, download=True, transform=transform_test)\n",
        "\n",
        "    # # Split training set into 10 partitions to simulate the individual dataset\n",
        "    # partition_size = len(trainset) // NUM_CLIENTS\n",
        "    # lengths = [partition_size] * NUM_CLIENTS\n",
        "    # datasets = random_split(trainset, lengths, torch.Generator().manual_seed(42))\n",
        "\n",
        "    # # Split each partition into train/val and create DataLoader\n",
        "    # trainloaders = []\n",
        "    # valloaders = []\n",
        "    # if divide:\n",
        "    #     for ds in datasets:\n",
        "    #         len_val = len(ds) // 10     # 10 % validation set\n",
        "    #         len_train = len(ds) - len_val\n",
        "    #         lengths = [len_train, len_val]\n",
        "    #         ds_train, ds_val = random_split(ds, lengths, torch.Generator().manual_seed(42))\n",
        "    #         trainloaders.append(DataLoader(ds_train, batch_size=BATCH_SIZE, shuffle=True))\n",
        "    #         valloaders.append(DataLoader(ds_val, batch_size=BATCH_SIZE))\n",
        "    # else:\n",
        "    #     trainloaders.append(DataLoader(trainset, batch_size=128, shuffle=True))\n",
        "    trainloader = DataLoader(trainset, batch_size=BATCH_SIZE)\n",
        "    testloader = DataLoader(testset, batch_size=BATCH_SIZE)\n",
        "    #return trainloaders, valloaders, testloader\n",
        "    return trainloader, testloader\n",
        "\n",
        "#trainloaders, valloaders, testloader = load_datasets(divide=False)\n",
        "trainloader, testloader = load_datasets(divide=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z-skjIVJ_0pc"
      },
      "source": [
        "Take a look at the first batch of images and labels in the first training set (i.e., trainloaders[0]) before we move on."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nwBBv_xr_8it"
      },
      "outputs": [],
      "source": [
        "images, labels = next(iter(trainloaders[0]))\n",
        "\n",
        "# Reshape and convert images to a NumPy array\n",
        "# matplotlib requires images with the shape (hight, width, 3)\n",
        "images = images.permute(0, 2, 3, 1).numpy()\n",
        "# Denormalize\n",
        "images = images / 2 + 0.5\n",
        "\n",
        "# Create a figure and a grid of subplots\n",
        "fig, axs = plt.subplots(4, 8, figsize=(12, 6))\n",
        "\n",
        "# Loop over the images and plot them\n",
        "for i, ax in enumerate(axs.flat):\n",
        "    ax.imshow(images[i])\n",
        "    ax.set_title(CLASSES[labels[i]])\n",
        "    ax.axis(\"off\")\n",
        "\n",
        "# Show the plot\n",
        "fig.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F0lPsARpAuqe"
      },
      "source": [
        "# Step 1: Centralized Training with PyTorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Ycgu5y4kkHX"
      },
      "source": [
        "## Resnet-50\n",
        "[github](https://github.com/kuangliu/pytorch-cifar/blob/master/models/resnet.py)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "l238MQnPiewB"
      },
      "outputs": [],
      "source": [
        "# Resnet-18\n",
        "# https://github.com/kuangliu/pytorch-cifar/blob/master/models/resnet.py\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "    \n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(\n",
        "            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
        "                               stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion*planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion*planes,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(self.expansion*planes)\n",
        "            )\n",
        "        \n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
        "                               stride=stride, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.conv3 = nn.Conv2d(planes, self.expansion *\n",
        "                               planes, kernel_size=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion*planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion*planes,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(self.expansion*planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = F.relu(self.bn2(self.conv2(out)))\n",
        "        out = self.bn3(self.conv3(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, num_blocks, num_classes=10):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_planes=64\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3,\n",
        "                               stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
        "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
        "        self.linear = nn.Linear(512*block.expansion, num_classes)\n",
        "\n",
        "    def _make_layer(self, block, planes, num_blocks, stride):\n",
        "        strides = [stride] + [1] * (num_blocks-1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_planes, planes, stride))\n",
        "            self.in_planes = planes * block.expansion\n",
        "        return nn.Sequential(*layers)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = F.avg_pool2d(out, 4)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "        return out\n",
        "\n",
        "def ResNet18():\n",
        "    return ResNet(BasicBlock, [2, 2, 2, 2])\n",
        "\n",
        "def ResNet50():\n",
        "    return ResNet(Bottleneck, [3, 4, 6, 3])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "9GgH5VGIFTk8"
      },
      "outputs": [],
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gTnxTPPjMQGi"
      },
      "source": [
        "## Train configuration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "ZjwxkNs9Q9Lf"
      },
      "outputs": [],
      "source": [
        "#net = ResNet50().to(DEVICE)\n",
        "net = Net().to(DEVICE)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.01,\n",
        "                      momentum=0.9, weight_decay=5e-4)\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pPRCVl2_5Qbw"
      },
      "source": [
        "Training and test functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "kBdcf1M95UFo"
      },
      "outputs": [],
      "source": [
        "def train(net, trainloader):\n",
        "    \"\"\"Train the network on the training set.\"\"\"\n",
        "    net.train()\n",
        "    train_loss, correct, total = 0, 0, 0\n",
        "\n",
        "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
        "        inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += targets.size(0)\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "    train_loss /= len(trainloader.dataset)\n",
        "    accuracy = correct / total\n",
        "\n",
        "    return train_loss, accuracy\n",
        "\n",
        "\n",
        "def test(net, testloader):\n",
        "    \"\"\"Evaluate the network on the entire test set.\"\"\"\n",
        "    net.eval()\n",
        "    test_loss, correct, total = 0, 0, 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
        "            inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "            test_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "    \n",
        "    test_loss /= len(testloader)\n",
        "    accuracy = correct / total\n",
        "\n",
        "    return test_loss, accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_GpVfSo7tHX"
      },
      "source": [
        "## Training the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 900 entries, 0 to 899\n",
            "Data columns (total 5 columns):\n",
            " #   Column      Non-Null Count  Dtype  \n",
            "---  ------      --------------  -----  \n",
            " 0   round       900 non-null    int64  \n",
            " 1   strategy    900 non-null    object \n",
            " 2   c_loss      801 non-null    float64\n",
            " 3   c_accuracy  900 non-null    float64\n",
            " 4   d_accuracy  900 non-null    float64\n",
            "dtypes: float64(3), int64(1), object(1)\n",
            "memory usage: 35.3+ KB\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "result_path = \"./log.csv\"\n",
        "\n",
        "df_final = pd.read_csv(result_path)\n",
        "print(df_final.info())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Ct8ZcuVe7u6v"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1\n",
            "Saving...(epoch 1)\n",
            "Epoch: 2\n",
            "Epoch: 3\n",
            "Epoch: 4\n",
            "Epoch: 5\n",
            "Epoch: 6\n",
            "Epoch: 7\n",
            "Epoch: 8\n",
            "Epoch: 9\n",
            "Epoch: 10\n",
            "Epoch 10: validation loss 2.305295038826858, accuracy 0.1026\n",
            "Epoch: 11\n",
            "Epoch: 12\n",
            "Epoch: 13\n",
            "Epoch: 14\n",
            "Epoch: 15\n",
            "Epoch: 16\n",
            "Epoch: 17\n",
            "Epoch: 18\n",
            "Epoch: 19\n",
            "Epoch: 20\n",
            "Epoch 20: validation loss 2.305295038826858, accuracy 0.1026\n",
            "Epoch: 21\n",
            "Epoch: 22\n",
            "Epoch: 23\n",
            "Epoch: 24\n",
            "Epoch: 25\n",
            "Epoch: 26\n",
            "Epoch: 27\n",
            "Epoch: 28\n",
            "Epoch: 29\n",
            "Epoch: 30\n",
            "Epoch 30: validation loss 2.305295038826858, accuracy 0.1026\n",
            "Epoch: 31\n",
            "Epoch: 32\n",
            "Epoch: 33\n",
            "Epoch: 34\n",
            "Epoch: 35\n",
            "Epoch: 36\n",
            "Epoch: 37\n",
            "Epoch: 38\n",
            "Epoch: 39\n",
            "Epoch: 40\n",
            "Epoch 40: validation loss 2.305295038826858, accuracy 0.1026\n",
            "Epoch: 41\n",
            "Epoch: 42\n",
            "Epoch: 43\n",
            "Epoch: 44\n",
            "Epoch: 45\n",
            "Epoch: 46\n",
            "Epoch: 47\n",
            "Epoch: 48\n",
            "Epoch: 49\n",
            "Epoch: 50\n",
            "Epoch 50: validation loss 2.305295038826858, accuracy 0.1026\n",
            "Epoch: 51\n",
            "Epoch: 52\n",
            "Epoch: 53\n",
            "Epoch: 54\n",
            "Epoch: 55\n",
            "Epoch: 56\n",
            "Epoch: 57\n",
            "Epoch: 58\n",
            "Epoch: 59\n",
            "Epoch: 60\n",
            "Epoch 60: validation loss 2.305295038826858, accuracy 0.1026\n",
            "Epoch: 61\n",
            "Epoch: 62\n",
            "Epoch: 63\n",
            "Epoch: 64\n",
            "Epoch: 65\n",
            "Epoch: 66\n",
            "Epoch: 67\n",
            "Epoch: 68\n",
            "Epoch: 69\n",
            "Epoch: 70\n",
            "Epoch 70: validation loss 2.305295038826858, accuracy 0.1026\n",
            "Epoch: 71\n",
            "Epoch: 72\n",
            "Epoch: 73\n",
            "Epoch: 74\n",
            "Epoch: 75\n",
            "Epoch: 76\n",
            "Epoch: 77\n",
            "Epoch: 78\n",
            "Epoch: 79\n",
            "Epoch: 80\n",
            "Epoch 80: validation loss 2.305295038826858, accuracy 0.1026\n",
            "Epoch: 81\n",
            "Epoch: 82\n",
            "Epoch: 83\n",
            "Epoch: 84\n",
            "Epoch: 85\n",
            "Epoch: 86\n",
            "Epoch: 87\n",
            "Epoch: 88\n",
            "Epoch: 89\n",
            "Epoch: 90\n",
            "Epoch 90: validation loss 2.305295038826858, accuracy 0.1026\n",
            "Epoch: 91\n",
            "Epoch: 92\n",
            "Epoch: 93\n",
            "Epoch: 94\n",
            "Epoch: 95\n",
            "Epoch: 96\n",
            "Epoch: 97\n",
            "Epoch: 98\n",
            "Epoch: 99\n",
            "Epoch: 100\n",
            "Epoch 100: validation loss 2.305295038826858, accuracy 0.1026\n",
            "Final test set performance:\n",
            "\tloss 2.305295038826858\n",
            "\taccuracy 0.1026\n"
          ]
        }
      ],
      "source": [
        "save_path = \"../result/best_ckpt.pth\"\n",
        "result_path = \"./log.csv\"\n",
        "\n",
        "df_final = pd.read_csv(result_path)\n",
        "\n",
        "\n",
        "#trainloader = trainloaders[0]\n",
        "#valloader = valloaders[0]\n",
        "#net = ResNet50().to(DEVICE)\n",
        "#net = Net().to(DEVICE)\n",
        "\n",
        "best_acc = 0\n",
        "for epoch in range(1, 101):\n",
        "    print(f\"Epoch: {epoch}\")\n",
        "    train_loss, _ = train(net, trainloader)\n",
        "    test_loss, accuracy = test(net, testloader)\n",
        "    scheduler.step()\n",
        "    if epoch % 10 == 0:\n",
        "        print(f\"Epoch {epoch}: validation loss {test_loss}, accuracy {accuracy}\")\n",
        "    if best_acc < accuracy:\n",
        "        print(f'Saving...(epoch {epoch})')\n",
        "\n",
        "        state = {\n",
        "            'net': net.state_dict(),\n",
        "            'acc': accuracy,\n",
        "            'epoch': epoch,\n",
        "        }\n",
        "        torch.save(state, save_path)\n",
        "        best_acc = accuracy\n",
        "    \n",
        "    df_result = pd.DataFrame()\n",
        "    df_result['round'] = epoch,\n",
        "    df_result['strategy'] = 'Central',\n",
        "    df_result['c_loss'] = test_loss,\n",
        "    df_result['c_accuracy'] = accuracy,\n",
        "    df_result['d_accuracy'] = 0.0\n",
        "\n",
        "    df_final = pd.concat([df_final, df_result], axis=0)\n",
        "\n",
        "loss, accuracy = test(net, testloader)\n",
        "print(f\"Final test set performance:\\n\\tloss {loss}\\n\\taccuracy {accuracy}\")\n",
        "\n",
        "df_final.to_csv(result_path, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Huy3XghlgCwk",
        "outputId": "c982132e-23ba-43d1-8904-2de11bd57b21"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Final test set performance:\n",
            "\tloss 0.25099298034947887\n",
            "\taccuracy 0.9495\n"
          ]
        }
      ],
      "source": [
        "best_model = torch.load(save_path)\n",
        "\n",
        "net = ResNet50().to(DEVICE)\n",
        "net.load_state_dict(best_model['net'])\n",
        "\n",
        "loss, accuracy = test(net, testloader)\n",
        "print(f\"Final test set performance:\\n\\tloss {loss}\\n\\taccuracy {accuracy}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uGaV0t-G8Ity"
      },
      "source": [
        "# Step 2 : Federated Learning with Flower"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q1D17MLAAp3T"
      },
      "source": [
        "## Config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "63n_nB-GArdK"
      },
      "outputs": [],
      "source": [
        "# General\n",
        "NUM_CLIENTS = 10\n",
        "BATCH_SIZE = 128"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MuNP1bnohfPc"
      },
      "source": [
        "## Make well-balanced dataset for FL clients"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7qxQX2gInrQU",
        "outputId": "f4a7b2f2-2090-4ef8-aa2c-7b470e672312"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "50000 10000\n"
          ]
        }
      ],
      "source": [
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "trainset = CIFAR10(\"./dataset\", train=True, download=True, transform=transform_train)\n",
        "testset = CIFAR10(\"./dataset\", train=False, download=True, transform=transform_test)\n",
        "\n",
        "print(len(trainset), len(testset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "b6xIKD-CovZB"
      },
      "outputs": [],
      "source": [
        "li_trainset = [torch.empty([0, 3, 32, 32]) for _ in range(10)]\n",
        "labels = [[] for _ in range(10)]\n",
        "\n",
        "for x, label in trainset:\n",
        "    labels[label].append(label)\n",
        "    li_trainset[label] = torch.cat((li_trainset[label], x[None, :]), dim=0)\n",
        "    \n",
        "labels = [torch.tensor(x) for x in labels]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MsHufFHuy0PO",
        "outputId": "cc48565b-1ea0-40f2-b674-2b096eeb0c17"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5000 40\n"
          ]
        }
      ],
      "source": [
        "d_train = [torch.empty([0, 3, 32, 32]) for _ in range(NUM_CLIENTS)]\n",
        "d_train_labels = [torch.tensor([], dtype=int) for _ in range(NUM_CLIENTS)]\n",
        "ds_clients = []         # dataset for each client\n",
        "dl_clients = []         # dataloader for each client\n",
        "\n",
        "\n",
        "for ds, label in zip(li_trainset, labels):\n",
        "    indices = torch.randperm(5000)\n",
        "    ds = ds[indices]\n",
        "    label = label[indices]\n",
        "    num_data = 5000 // NUM_CLIENTS\n",
        "    for i in range(NUM_CLIENTS):\n",
        "        d_train[i] = torch.cat((d_train[i], ds[i*num_data : (i+1)*num_data]), dim=0)\n",
        "        d_train_labels[i] = torch.cat((d_train_labels[i], label[i*num_data : (i+1)*num_data]))\n",
        "\n",
        "for i in range(NUM_CLIENTS):\n",
        "    indices = torch.randperm(5000)\n",
        "    d_train[i] = d_train[i][indices]\n",
        "    d_train_labels[i] = d_train_labels[i][indices]\n",
        "    ds_client = TensorDataset(d_train[i], d_train_labels[i])\n",
        "    dl_client = DataLoader(\n",
        "        ds_client,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle=True,\n",
        "    )\n",
        "    ds_clients.append(ds_client)\n",
        "    dl_clients.append(dl_client)\n",
        "\n",
        "testloader = DataLoader(\n",
        "    testset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,\n",
        ")\n",
        "\n",
        "print(len(ds_clients[0]), len(dl_clients[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xoAagMJFCOMC"
      },
      "source": [
        "## Train/Test function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "n42uW_eMCP6E"
      },
      "outputs": [],
      "source": [
        "def train(net, trainloader, epochs=1):\n",
        "    \"\"\"Train the network on the training set.\"\"\"\n",
        "    net.train()\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.SGD(net.parameters(), lr=0.01,\n",
        "                        momentum=0.9, weight_decay=5e-4)\n",
        "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "\n",
        "        for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
        "            inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "        scheduler.step()\n",
        "\n",
        "\n",
        "def test(net, testloader):\n",
        "    \"\"\"Evaluate the network on the entire test set.\"\"\"\n",
        "    \n",
        "    net.eval()\n",
        "    test_loss, correct, total = 0, 0, 0\n",
        "    \n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
        "            inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "            test_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "    \n",
        "    test_loss /= len(testloader)\n",
        "    accuracy = correct / total\n",
        "\n",
        "    return test_loss, accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o6SAFDr78LrC"
      },
      "source": [
        "## Updating model parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "pMUxzers8NU6"
      },
      "outputs": [],
      "source": [
        "# def get_parameters(net) -> List[np.ndarray]:\n",
        "#     return [val.cpu().numpy() for _, val in net.state_dict().items()]\n",
        "\n",
        "# def set_parameters(net, parameters: List[np.ndarray]):\n",
        "#     params_dict = zip(net.state_dict().keys(), parameters)\n",
        "#     state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n",
        "#     net.load_state_dict(state_dict, strict=True)\n",
        "\n",
        "\n",
        "def get_parameters(net) -> List[np.ndarray]:\n",
        "    return [val.cpu().numpy() for _, val in net.state_dict().items()]\n",
        "\n",
        "def set_parameters(net, parameters: List[np.ndarray]):\n",
        "    #print(f\"Net: {len(net.state_dict().keys())} Params: {len(parameters)}\")\n",
        "    params_dict = zip(net.state_dict().keys(), parameters)\n",
        "    # for k, v in params_dict:\n",
        "    #     continue\n",
        "    state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n",
        "    net.load_state_dict(state_dict, strict=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iET4g1U88t4m"
      },
      "source": [
        "## Implementing a Flower client"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "bYIyDQTc8zW1"
      },
      "outputs": [],
      "source": [
        "class FlowerClient(fl.client.NumPyClient):\n",
        "    def __init__(self, net, trainloader, valloader):\n",
        "        self.net = net\n",
        "        self.trainloader = trainloader\n",
        "        self.valloader = valloader\n",
        "    \n",
        "    def get_parameters(self, config):\n",
        "        return get_parameters(self.net)\n",
        "\n",
        "    def fit(self, parameters, config):\n",
        "        set_parameters(self.net, parameters)\n",
        "        train(self.net, self.trainloader, epochs=1)\n",
        "        return get_parameters(self.net), len(self.trainloader), {}\n",
        "    \n",
        "    def evaluate(self, parameters, config):\n",
        "        set_parameters(self.net, parameters)\n",
        "        loss, accuracy = test(self.net, self.valloader)\n",
        "        return float(loss), len(self.valloader), {\"accuracy\": float(accuracy)}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XKO6jC9u9Vp5"
      },
      "source": [
        "## Using the Virtual Client Engine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "0F-F_ltw9UWZ"
      },
      "outputs": [],
      "source": [
        "def client_fn(cid: str) -> FlowerClient:\n",
        "    \"\"\"Create a Flower client representing a single organization.\"\"\"\n",
        "\n",
        "    # Load model\n",
        "    net = Net().to(DEVICE)\n",
        "    #net = ResNet50().to(DEVICE)\n",
        "\n",
        "    # Load data (CIFAR-10)\n",
        "    # Note: each client gets a different trainloader/valloader, so each client \n",
        "    # will train and evaluate on their own unique data\n",
        "    trainloader = dl_clients[int(cid)]\n",
        "    #valloader = valloaders[int(cid)]\n",
        "    valloader = testloader\n",
        "\n",
        "    # Create a single Flower client representing a single organization\n",
        "    return FlowerClient(net, trainloader, valloader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ybq8tUOOQiWn"
      },
      "source": [
        "## Evaluate global model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "CvNSTVgtQvnA"
      },
      "outputs": [],
      "source": [
        "def evaluate(\n",
        "    server_round: int, parameters: fl.common.NDArrays, config: Dict[str, fl.common.Scalar]\n",
        ") -> Optional[Tuple[float, Dict[str, fl.common.Scalar]]]:\n",
        "\n",
        "    net = Net().to(DEVICE)\n",
        "    #net = ResNet50().to(DEVICE)\n",
        "    set_parameters(net, parameters)\n",
        "    net = net.to(DEVICE)\n",
        "    loss, accuracy = test(net, testloader)\n",
        "    \n",
        "    return loss, {\"loss\": loss, \"accuracy\": accuracy} # The return type must be (loss, metric tuple) form"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d6l4U_dkCUnY"
      },
      "source": [
        "## Aggregate evaluation of local model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "7FgrfabPCWwp"
      },
      "outputs": [],
      "source": [
        "def weighted_average(metrics: List[Tuple[int, Metrics]]) -> Metrics:\n",
        "    # Multiply accuracy of each client by number of examples used\n",
        "    accuracies = [num_examples * m[\"accuracy\"] for num_examples, m in metrics]\n",
        "    examples = [num_examples for num_examples, _ in metrics]\n",
        "    \n",
        "    # Aggregate and return custom metric (weighted average)\n",
        "    return {\"accuracy\": sum(accuracies) / sum(examples)}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ED5wYI0_Y-Ta"
      },
      "source": [
        "## Create FL strategy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "JqC_oyI8ZCpG"
      },
      "outputs": [],
      "source": [
        "# Create FedAvg strategy\n",
        "strategy = fl.server.strategy.FedAvg(\n",
        "    fraction_fit=1.0,\n",
        "    fraction_evaluate=0.5,\n",
        "    min_fit_clients=10,\n",
        "    min_evaluate_clients=5,\n",
        "    min_available_clients=10,\n",
        "    evaluate_metrics_aggregation_fn=weighted_average,   # aggregate evaluation of local model\n",
        "    evaluate_fn=evaluate,   # evaluate global model\n",
        "    initial_parameters=fl.common.ndarrays_to_parameters(get_parameters(Net())),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "fedavg = fl.server.strategy.FedAvg(\n",
        "    fraction_fit=1.0,\n",
        "    fraction_evaluate=0.5,\n",
        "    min_fit_clients=10,\n",
        "    min_evaluate_clients=5,\n",
        "    min_available_clients=10,\n",
        "    evaluate_metrics_aggregation_fn=weighted_average,   # aggregate evaluation of local model\n",
        "    evaluate_fn=evaluate,   # evaluate global model\n",
        "    initial_parameters=fl.common.ndarrays_to_parameters(get_parameters(Net())),\n",
        ")\n",
        "\n",
        "fedavgM = fl.server.strategy.FedAvgM(\n",
        "    fraction_fit=1.0,\n",
        "    fraction_evaluate=0.5,\n",
        "    min_fit_clients=10,\n",
        "    min_evaluate_clients=5,\n",
        "    min_available_clients=10,\n",
        "    evaluate_metrics_aggregation_fn=weighted_average,   # aggregate evaluation of local model\n",
        "    evaluate_fn=evaluate,   # evaluate global model\n",
        "    initial_parameters=fl.common.ndarrays_to_parameters(get_parameters(Net())),\n",
        ")\n",
        "\n",
        "qfedavg = fl.server.strategy.QFedAvg(\n",
        "    fraction_fit=1.0,\n",
        "    fraction_evaluate=0.5,\n",
        "    min_fit_clients=10,\n",
        "    min_evaluate_clients=5,\n",
        "    min_available_clients=10,\n",
        "    evaluate_metrics_aggregation_fn=weighted_average,   # aggregate evaluation of local model\n",
        "    evaluate_fn=evaluate,   # evaluate global model\n",
        "    initial_parameters=fl.common.ndarrays_to_parameters(get_parameters(Net())),\n",
        ")\n",
        "\n",
        "ftfedavg = fl.server.strategy.FaultTolerantFedAvg(\n",
        "    fraction_fit=1.0,\n",
        "    fraction_evaluate=0.5,\n",
        "    min_fit_clients=10,\n",
        "    min_evaluate_clients=5,\n",
        "    min_available_clients=10,\n",
        "    evaluate_metrics_aggregation_fn=weighted_average,   # aggregate evaluation of local model\n",
        "    evaluate_fn=evaluate,   # evaluate global model\n",
        "    initial_parameters=fl.common.ndarrays_to_parameters(get_parameters(Net())),\n",
        ")\n",
        "\n",
        "fedopt = fl.server.strategy.FedOpt(\n",
        "    fraction_fit=1.0,\n",
        "    fraction_evaluate=0.5,\n",
        "    min_fit_clients=10,\n",
        "    min_evaluate_clients=5,\n",
        "    min_available_clients=10,\n",
        "    evaluate_metrics_aggregation_fn=weighted_average,   # aggregate evaluation of local model\n",
        "    evaluate_fn=evaluate,   # evaluate global model\n",
        "    initial_parameters=fl.common.ndarrays_to_parameters(get_parameters(Net())),\n",
        ")\n",
        "\n",
        "fedprox = fl.server.strategy.FedProx(\n",
        "    fraction_fit=1.0,\n",
        "    fraction_evaluate=0.5,\n",
        "    min_fit_clients=10,\n",
        "    min_evaluate_clients=5,\n",
        "    min_available_clients=10,\n",
        "    evaluate_metrics_aggregation_fn=weighted_average,   # aggregate evaluation of local model\n",
        "    evaluate_fn=evaluate,   # evaluate global model\n",
        "    initial_parameters=fl.common.ndarrays_to_parameters(get_parameters(Net())),\n",
        "    proximal_mu=0.1,\n",
        ")\n",
        "\n",
        "fedadagrad = fl.server.strategy.FedAdagrad(\n",
        "    fraction_fit=1.0,\n",
        "    fraction_evaluate=0.5,\n",
        "    min_fit_clients=10,\n",
        "    min_evaluate_clients=5,\n",
        "    min_available_clients=10,\n",
        "    evaluate_metrics_aggregation_fn=weighted_average,   # aggregate evaluation of local model\n",
        "    evaluate_fn=evaluate,   # evaluate global model\n",
        "    initial_parameters=fl.common.ndarrays_to_parameters(get_parameters(Net())),\n",
        ")\n",
        "\n",
        "fedadam = fl.server.strategy.FedAdam(\n",
        "    fraction_fit=1.0,\n",
        "    fraction_evaluate=0.5,\n",
        "    min_fit_clients=10,\n",
        "    min_evaluate_clients=5,\n",
        "    min_available_clients=10,\n",
        "    evaluate_metrics_aggregation_fn=weighted_average,   # aggregate evaluation of local model\n",
        "    evaluate_fn=evaluate,   # evaluate global model\n",
        "    initial_parameters=fl.common.ndarrays_to_parameters(get_parameters(Net())),\n",
        ")\n",
        "\n",
        "fedyogi = fl.server.strategy.FedYogi(\n",
        "    fraction_fit=1.0,\n",
        "    fraction_evaluate=0.5,\n",
        "    min_fit_clients=10,\n",
        "    min_evaluate_clients=5,\n",
        "    min_available_clients=10,\n",
        "    evaluate_metrics_aggregation_fn=weighted_average,   # aggregate evaluation of local model\n",
        "    evaluate_fn=evaluate,   # evaluate global model\n",
        "    initial_parameters=fl.common.ndarrays_to_parameters(get_parameters(Net())),\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vjS94lE7ZE-G"
      },
      "source": [
        "## FL simulation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wKJShJtxZHRP"
      },
      "source": [
        "### simulation parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "KSfafyrzZKSn"
      },
      "outputs": [],
      "source": [
        "num_rounds = 2\n",
        "\n",
        "# Specify client resources if you need GPU (defaults to 1 CPU and 0 GPU)\n",
        "client_resources = None\n",
        "if DEVICE.type == \"cuda\":\n",
        "    client_resources = {\"num_gpus\": 1}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ql5d0c_xZPYf"
      },
      "source": [
        "### Simulate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XR3BQS9mCu7t",
        "outputId": "a6e03cf1-1400-499d-f667-d4eb5e0bc2f5"
      },
      "outputs": [],
      "source": [
        "# Start simulation\n",
        "hist = fl.simulation.start_simulation(\n",
        "    client_fn=client_fn,\n",
        "    num_clients=NUM_CLIENTS,\n",
        "    config=fl.server.ServerConfig(num_rounds=num_rounds),\n",
        "    #strategy=strategy,\n",
        "    strategy=fedAvgM,\n",
        "    client_resources=client_resources,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_final = pd.DataFrame()\n",
        "strategies = {\n",
        "    'FedAvg': fedavg,\n",
        "    'FedAvgM': fedavgM,\n",
        "    'QFedAvg': qfedavg,\n",
        "    'FaultTolerantFedAvg': ftfedavg,\n",
        "    'FedOpt': fedopt,\n",
        "    'FedProx': fedprox,\n",
        "    'FedAdagrad': fedadagrad,\n",
        "    'FedAdam': fedadam,\n",
        "    'FedYogi': fedyogi,\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FedAvg FedAvg(accept_failures=True)\n",
            "FedAvgM FedAvgM(accept_failures=True)\n",
            "QFedAvg QffedAvg(learning_rate=0.1, q_param=0.2, pre_weights=None)\n",
            "FaultTolerantFedAvg FaultTolerantFedAvg()\n",
            "FedOpt FedOpt(accept_failures=True)\n",
            "FedProx FedProx(accept_failures=True)\n",
            "FedAdagrad FedAdagrad(accept_failures=True)\n",
            "FedAdam FedAdam(accept_failures=True)\n",
            "FedYogi FedYogi(accept_failures=True)\n"
          ]
        }
      ],
      "source": [
        "for k, v in strategies.items():\n",
        "    print(k, v)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_123rXXVZwqL",
        "outputId": "82b549f0-81a6-4e2d-d899-2bd10c0810e4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO flwr 2023-05-01 10:19:22,930 | app.py:146 | Starting Flower simulation, config: ServerConfig(num_rounds=2, round_timeout=None)\n",
            "2023-05-01 10:19:27,157\tINFO worker.py:1625 -- Started a local Ray instance.\n",
            "INFO flwr 2023-05-01 10:19:27,751 | app.py:180 | Flower VCE: Ray initialized with resources: {'GPU': 1.0, 'object_store_memory': 36148646707.0, 'node:172.17.0.2': 1.0, 'memory': 74346842317.0, 'accelerator_type:RTX': 1.0, 'CPU': 16.0}\n",
            "INFO flwr 2023-05-01 10:19:27,752 | server.py:86 | Initializing global parameters\n",
            "INFO flwr 2023-05-01 10:19:27,752 | server.py:269 | Using initial parameters provided by strategy\n",
            "INFO flwr 2023-05-01 10:19:27,752 | server.py:88 | Evaluating initial parameters\n",
            "INFO flwr 2023-05-01 10:19:28,803 | server.py:91 | initial parameters (loss, other metrics): 2.3045961736123775, {'loss': 2.3045961736123775, 'accuracy': 0.0816}\n",
            "INFO flwr 2023-05-01 10:19:28,804 | server.py:101 | FL starting\n",
            "DEBUG flwr 2023-05-01 10:19:28,804 | server.py:218 | fit_round 1: strategy sampled 10 clients (out of 10)\n",
            "DEBUG flwr 2023-05-01 10:19:54,328 | server.py:232 | fit_round 1 received 10 results and 0 failures\n",
            "WARNING flwr 2023-05-01 10:19:54,340 | fedavg.py:243 | No fit_metrics_aggregation_fn provided\n",
            "INFO flwr 2023-05-01 10:19:55,388 | server.py:119 | fit progress: (1, 2.2834927884838248, {'loss': 2.2834927884838248, 'accuracy': 0.1458}, 26.58396272896789)\n",
            "DEBUG flwr 2023-05-01 10:19:55,388 | server.py:168 | evaluate_round 1: strategy sampled 5 clients (out of 10)\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[36], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfor\u001b[39;00m sname, strategy \u001b[39min\u001b[39;00m strategies\u001b[39m.\u001b[39mitems():\n\u001b[0;32m----> 3\u001b[0m     hist \u001b[39m=\u001b[39m fl\u001b[39m.\u001b[39;49msimulation\u001b[39m.\u001b[39;49mstart_simulation(\n\u001b[1;32m      4\u001b[0m         client_fn\u001b[39m=\u001b[39;49mclient_fn,\n\u001b[1;32m      5\u001b[0m         num_clients\u001b[39m=\u001b[39;49mNUM_CLIENTS,\n\u001b[1;32m      6\u001b[0m         config\u001b[39m=\u001b[39;49mfl\u001b[39m.\u001b[39;49mserver\u001b[39m.\u001b[39;49mServerConfig(num_rounds\u001b[39m=\u001b[39;49mnum_rounds),\n\u001b[1;32m      7\u001b[0m         strategy\u001b[39m=\u001b[39;49mstrategy,\n\u001b[1;32m      8\u001b[0m         client_resources\u001b[39m=\u001b[39;49mclient_resources,\n\u001b[1;32m      9\u001b[0m     )\n\u001b[1;32m     11\u001b[0m     df_result \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame()\n\u001b[1;32m     12\u001b[0m     df_result[\u001b[39m'\u001b[39m\u001b[39mround\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m [i \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, num_rounds \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m)]\n",
            "File \u001b[0;32m~/anaconda3/envs/flower/lib/python3.9/site-packages/flwr/simulation/app.py:197\u001b[0m, in \u001b[0;36mstart_simulation\u001b[0;34m(client_fn, num_clients, clients_ids, client_resources, server, config, strategy, client_manager, ray_init_args, keep_initialised)\u001b[0m\n\u001b[1;32m    194\u001b[0m     initialized_server\u001b[39m.\u001b[39mclient_manager()\u001b[39m.\u001b[39mregister(client\u001b[39m=\u001b[39mclient_proxy)\n\u001b[1;32m    196\u001b[0m \u001b[39m# Start training\u001b[39;00m\n\u001b[0;32m--> 197\u001b[0m hist \u001b[39m=\u001b[39m _fl(\n\u001b[1;32m    198\u001b[0m     server\u001b[39m=\u001b[39;49minitialized_server,\n\u001b[1;32m    199\u001b[0m     config\u001b[39m=\u001b[39;49minitialized_config,\n\u001b[1;32m    200\u001b[0m )\n\u001b[1;32m    202\u001b[0m event(EventType\u001b[39m.\u001b[39mSTART_SIMULATION_LEAVE)\n\u001b[1;32m    204\u001b[0m \u001b[39mreturn\u001b[39;00m hist\n",
            "File \u001b[0;32m~/anaconda3/envs/flower/lib/python3.9/site-packages/flwr/server/app.py:217\u001b[0m, in \u001b[0;36m_fl\u001b[0;34m(server, config)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_fl\u001b[39m(\n\u001b[1;32m    213\u001b[0m     server: Server,\n\u001b[1;32m    214\u001b[0m     config: ServerConfig,\n\u001b[1;32m    215\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m History:\n\u001b[1;32m    216\u001b[0m     \u001b[39m# Fit model\u001b[39;00m\n\u001b[0;32m--> 217\u001b[0m     hist \u001b[39m=\u001b[39m server\u001b[39m.\u001b[39;49mfit(num_rounds\u001b[39m=\u001b[39;49mconfig\u001b[39m.\u001b[39;49mnum_rounds, timeout\u001b[39m=\u001b[39;49mconfig\u001b[39m.\u001b[39;49mround_timeout)\n\u001b[1;32m    218\u001b[0m     log(INFO, \u001b[39m\"\u001b[39m\u001b[39mapp_fit: losses_distributed \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m, \u001b[39mstr\u001b[39m(hist\u001b[39m.\u001b[39mlosses_distributed))\n\u001b[1;32m    219\u001b[0m     log(INFO, \u001b[39m\"\u001b[39m\u001b[39mapp_fit: metrics_distributed_fit \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m, \u001b[39mstr\u001b[39m(hist\u001b[39m.\u001b[39mmetrics_distributed_fit))\n",
            "File \u001b[0;32m~/anaconda3/envs/flower/lib/python3.9/site-packages/flwr/server/server.py:133\u001b[0m, in \u001b[0;36mServer.fit\u001b[0;34m(self, num_rounds, timeout)\u001b[0m\n\u001b[1;32m    128\u001b[0m     history\u001b[39m.\u001b[39madd_metrics_centralized(\n\u001b[1;32m    129\u001b[0m         server_round\u001b[39m=\u001b[39mcurrent_round, metrics\u001b[39m=\u001b[39mmetrics_cen\n\u001b[1;32m    130\u001b[0m     )\n\u001b[1;32m    132\u001b[0m \u001b[39m# Evaluate model on a sample of available clients\u001b[39;00m\n\u001b[0;32m--> 133\u001b[0m res_fed \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mevaluate_round(server_round\u001b[39m=\u001b[39;49mcurrent_round, timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[1;32m    134\u001b[0m \u001b[39mif\u001b[39;00m res_fed:\n\u001b[1;32m    135\u001b[0m     loss_fed, evaluate_metrics_fed, _ \u001b[39m=\u001b[39m res_fed\n",
            "File \u001b[0;32m~/anaconda3/envs/flower/lib/python3.9/site-packages/flwr/server/server.py:177\u001b[0m, in \u001b[0;36mServer.evaluate_round\u001b[0;34m(self, server_round, timeout)\u001b[0m\n\u001b[1;32m    168\u001b[0m log(\n\u001b[1;32m    169\u001b[0m     DEBUG,\n\u001b[1;32m    170\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mevaluate_round \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m: strategy sampled \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m clients (out of \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    173\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_client_manager\u001b[39m.\u001b[39mnum_available(),\n\u001b[1;32m    174\u001b[0m )\n\u001b[1;32m    176\u001b[0m \u001b[39m# Collect `evaluate` results from all clients participating in this round\u001b[39;00m\n\u001b[0;32m--> 177\u001b[0m results, failures \u001b[39m=\u001b[39m evaluate_clients(\n\u001b[1;32m    178\u001b[0m     client_instructions,\n\u001b[1;32m    179\u001b[0m     max_workers\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_workers,\n\u001b[1;32m    180\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    181\u001b[0m )\n\u001b[1;32m    182\u001b[0m log(\n\u001b[1;32m    183\u001b[0m     DEBUG,\n\u001b[1;32m    184\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mevaluate_round \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m received \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m results and \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m failures\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[39mlen\u001b[39m(failures),\n\u001b[1;32m    188\u001b[0m )\n\u001b[1;32m    190\u001b[0m \u001b[39m# Aggregate the evaluation results\u001b[39;00m\n",
            "File \u001b[0;32m~/anaconda3/envs/flower/lib/python3.9/site-packages/flwr/server/server.py:394\u001b[0m, in \u001b[0;36mevaluate_clients\u001b[0;34m(client_instructions, max_workers, timeout)\u001b[0m\n\u001b[1;32m    389\u001b[0m \u001b[39mwith\u001b[39;00m concurrent\u001b[39m.\u001b[39mfutures\u001b[39m.\u001b[39mThreadPoolExecutor(max_workers\u001b[39m=\u001b[39mmax_workers) \u001b[39mas\u001b[39;00m executor:\n\u001b[1;32m    390\u001b[0m     submitted_fs \u001b[39m=\u001b[39m {\n\u001b[1;32m    391\u001b[0m         executor\u001b[39m.\u001b[39msubmit(evaluate_client, client_proxy, ins, timeout)\n\u001b[1;32m    392\u001b[0m         \u001b[39mfor\u001b[39;00m client_proxy, ins \u001b[39min\u001b[39;00m client_instructions\n\u001b[1;32m    393\u001b[0m     }\n\u001b[0;32m--> 394\u001b[0m     finished_fs, _ \u001b[39m=\u001b[39m concurrent\u001b[39m.\u001b[39;49mfutures\u001b[39m.\u001b[39;49mwait(\n\u001b[1;32m    395\u001b[0m         fs\u001b[39m=\u001b[39;49msubmitted_fs,\n\u001b[1;32m    396\u001b[0m         timeout\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,  \u001b[39m# Handled in the respective communication stack\u001b[39;49;00m\n\u001b[1;32m    397\u001b[0m     )\n\u001b[1;32m    399\u001b[0m \u001b[39m# Gather results\u001b[39;00m\n\u001b[1;32m    400\u001b[0m results: List[Tuple[ClientProxy, EvaluateRes]] \u001b[39m=\u001b[39m []\n",
            "File \u001b[0;32m~/anaconda3/envs/flower/lib/python3.9/concurrent/futures/_base.py:307\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(fs, timeout, return_when)\u001b[0m\n\u001b[1;32m    303\u001b[0m         \u001b[39mreturn\u001b[39;00m DoneAndNotDoneFutures(done, not_done)\n\u001b[1;32m    305\u001b[0m     waiter \u001b[39m=\u001b[39m _create_and_install_waiters(fs, return_when)\n\u001b[0;32m--> 307\u001b[0m waiter\u001b[39m.\u001b[39;49mevent\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[1;32m    308\u001b[0m \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m fs:\n\u001b[1;32m    309\u001b[0m     \u001b[39mwith\u001b[39;00m f\u001b[39m.\u001b[39m_condition:\n",
            "File \u001b[0;32m~/anaconda3/envs/flower/lib/python3.9/threading.py:581\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    579\u001b[0m signaled \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flag\n\u001b[1;32m    580\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 581\u001b[0m     signaled \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cond\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[1;32m    582\u001b[0m \u001b[39mreturn\u001b[39;00m signaled\n",
            "File \u001b[0;32m~/anaconda3/envs/flower/lib/python3.9/threading.py:312\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    311\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 312\u001b[0m         waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[1;32m    313\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    314\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "for sname, strategy in strategies.items():\n",
        "\n",
        "    hist = fl.simulation.start_simulation(\n",
        "        client_fn=client_fn,\n",
        "        num_clients=NUM_CLIENTS,\n",
        "        config=fl.server.ServerConfig(num_rounds=num_rounds),\n",
        "        strategy=strategy,\n",
        "        client_resources=client_resources,\n",
        "    )\n",
        "\n",
        "    df_result = pd.DataFrame()\n",
        "    df_result['round'] = [i for i in range(1, num_rounds + 1)]\n",
        "    df_result['strategy'] = sname\n",
        "\n",
        "    # centralized metrics\n",
        "    metrics_cen = list(hist.metrics_centralized.keys())\n",
        "    metrics_dis = list(hist.metrics_distributed.keys())\n",
        "\n",
        "    for metric in metrics_cen:\n",
        "        df_result[f\"c_{metric}\"] = [h[1] for h in hist.metrics_centralized[metric][1:]]\n",
        "    for metric in metrics_dis:\n",
        "        df_result[f\"d_{metric}\"] = [h[1] for h in hist.metrics_distributed[metric]]\n",
        "\n",
        "    df_final = pd.concat([df_final, df_result], axis=0)\n",
        "\n",
        "df_final.to_csv('./log.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u_kbKC2Beao-"
      },
      "source": [
        "# Plot the result graphs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hljaU7HJfEY2"
      },
      "outputs": [],
      "source": [
        "import plotly.graph_objects as go"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YBzRBSloemdh"
      },
      "source": [
        "round-loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t7rhw23Ngw7K",
        "outputId": "6888ecd0-7e7c-4891-f68f-882dcec52198"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.1    0.3069 0.3809 0.4196 0.4447 0.4649]\n"
          ]
        }
      ],
      "source": [
        "print(df_result['accuracy'].values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "o6JIz7kMeoki",
        "outputId": "53ff3884-30f1-457c-8c6b-11970662a947"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.18.2.min.js\"></script>                <div id=\"6eec7092-9e84-4155-acf3-8e9d8092f034\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"6eec7092-9e84-4155-acf3-8e9d8092f034\")) {                    Plotly.newPlot(                        \"6eec7092-9e84-4155-acf3-8e9d8092f034\",                        [{\"x\":[1,2,3,4,5],\"y\":[0.06166734161376953,0.053219888293743134,0.04960033710002899,0.047812195229530334,0.04614442213773728],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"title\":{\"text\":\"\"},\"xaxis\":{\"title\":{\"text\":\"round\"}},\"yaxis\":{\"title\":{\"text\":\"loss\"}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('6eec7092-9e84-4155-acf3-8e9d8092f034');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "fig = go.Figure()\n",
        "# Create and style traces\n",
        "fig.add_trace(\n",
        "    go.Scatter(\n",
        "        x=df_result['round'].values[1:],\n",
        "        y=df_result['loss'].values[1:],\n",
        "    )\n",
        ")\n",
        "\n",
        "fig.update_layout(\n",
        "    title=\"\",\n",
        "    xaxis_title=\"round\",\n",
        "    yaxis_title=\"loss\",\n",
        "    #plot_bgcolor=\"rgba(0,0,0,0)\",\n",
        ")\n",
        "\n",
        "fig.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "S8KbmwmJNvpu",
        "xkFq4GuQ-W3c",
        "2Ycgu5y4kkHX"
      ],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "flower",
      "language": "python",
      "name": "flower"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
